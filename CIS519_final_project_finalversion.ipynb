{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiRCcXroIcs2"
      },
      "source": [
        "# Welcome to our CIS 519 final project! \n",
        "## In this notebook, our goal is to apply ML/DL models to the dataset and extract the most supportable phrase or word of a given text according to an associated sentiment. Let :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xv1sIzFBP2B"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1hq2Lf7Qldw"
      },
      "source": [
        "## **import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK8jprSr92Eb",
        "outputId": "e40af307-8cb5-40b4-ffa9-a8adb7e8fb0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.7/dist-packages (0.18.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ],
      "source": [
        "#@title \n",
        "## Data preprocessing part\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "!pip install fuzzywuzzy\n",
        "from fuzzywuzzy import fuzz\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Seed setup\n",
        "# seed = 2022\n",
        "# random.seed(seed)\n",
        "# torch.manual_seed(seed)\n",
        "# torch.cuda.manual_seed_all(seed)\n",
        "# torch.cuda.manual_seed(seed)\n",
        "\n",
        "## Device detection\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZC40u8ZjdYH"
      },
      "source": [
        "##**Glove embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gyMAbZgjdYH",
        "outputId": "7d08e1cf-bab7-44ac-ffa3-7e0ea6c81224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-04-26 00:33:11--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2022-04-26 00:33:11--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  5.11MB/s    in 6m 51s  \n",
            "\n",
            "2022-04-26 00:40:02 (5.05 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n",
            "Archive:  glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n",
            "total 7643100\n",
            "drwxr-xr-x 1 root root       4096 Apr 26 00:40 .\n",
            "-rw-r--r-- 1 root root    3501243 Apr 26 00:32 train.csv\n",
            "drwxr-xr-x 1 root root       4096 Apr 26 00:31 ..\n",
            "drwxr-xr-x 1 root root       4096 Apr 19 14:23 sample_data\n",
            "drwxr-xr-x 1 root root       4096 Apr 19 14:22 .config\n",
            "-rw-r--r-- 1 root root 2176768927 Oct 24  2015 glove.840B.300d.zip\n",
            "-rw-rw-r-- 1 root root 5646236541 Oct 24  2015 glove.840B.300d.txt\n"
          ]
        }
      ],
      "source": [
        "!wget -nc https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "!unzip glove.840B.300d.zip\n",
        "!ls -lat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5t4asi9pVyt"
      },
      "outputs": [],
      "source": [
        "glove_file = \"glove.840B.300d.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ymhK-TGVFk0"
      },
      "source": [
        "# **1. Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqO-xuL1Ezrn"
      },
      "source": [
        "## **1.1 Data overview**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuB-5wwIE3dQ"
      },
      "source": [
        "First lets All data is stored in train.csv file with 27481 rows.\n",
        "\n",
        "The source of the data is from kaggle comepetitions: https://www.kaggle.com/competitions/tweet-sentiment-extraction/data?select=train.csv \n",
        "\n",
        "**Columns**\n",
        "\n",
        "- **textID** - unique ID for each piece of the text\n",
        "- **text** - the text of the tweet\n",
        "- **sentiment** - the general sentiment of the tweet\n",
        "- **selected_text** - the text that supports the tweet's sentiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EgBURtVKz3HY",
        "outputId": "5076a056-36d4-4e40-c0a8-bc6ed801b59a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-59a8c400-f121-4ce3-8600-b15c93b86593\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59a8c400-f121-4ce3-8600-b15c93b86593')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59a8c400-f121-4ce3-8600-b15c93b86593 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59a8c400-f121-4ce3-8600-b15c93b86593');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment  \n",
              "0  I`d have responded, if I were going   neutral  \n",
              "1                             Sooo SAD  negative  \n",
              "2                          bullying me  negative  \n",
              "3                       leave me alone  negative  \n",
              "4                        Sons of ****,  negative  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('/content/train.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KanpcFn_DuE-",
        "outputId": "19afbd62-2ef6-489e-b954-68014e3ab1c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(27481, 4)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhD6iA68D0Es",
        "outputId": "fa67882c-3065-4450-9d41-d9139fb97ddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27481 entries, 0 to 27480\n",
            "Data columns (total 4 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   textID         27481 non-null  object\n",
            " 1   text           27480 non-null  object\n",
            " 2   selected_text  27480 non-null  object\n",
            " 3   sentiment      27481 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 858.9+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv3gwGmkztj-"
      },
      "source": [
        "# **2. Data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-FQu0RQkCvr"
      },
      "outputs": [],
      "source": [
        "#@title Helper functions\n",
        "## Data preprocessing part\n",
        "def remove_hyperlinks(text):\n",
        "  hyperlinkfree=re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "  return hyperlinkfree\n",
        "\n",
        "def remove(text):\n",
        "  text=re.sub('\\S*\\d\\S*',' ',text) #Removing Numbers\n",
        "  text=re.sub('<.*?>+',' ',text)   #Removing Angular Brackets\n",
        "  text=re.sub('\\[.*?\\]',' ',text)  #Removing Square Brackets\n",
        "  text=re.sub('\\n',' ',text)       #Removing '\\n' character \n",
        "  text=re.sub('\\*+','<ABUSE>',text) #Replacing **** by ABUSE word\n",
        "  return text\n",
        "\n",
        "def remove_punctuation(text):\n",
        "  punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
        "  return punctuationfree\n",
        "\n",
        "def wrong_words(text,selected):\n",
        "  words=[]\n",
        "  text = str(text)\n",
        "  selected= str(selected)\n",
        "  text=text.split()\n",
        "  selected=selected.split()\n",
        "  for i in selected:\n",
        "    if i not in text:\n",
        "      words.append(i)\n",
        "  if len(words)>0:\n",
        "    return \" \".join(words)\n",
        "  else:\n",
        "    return '++++'\n",
        "\n",
        "def remove_text(x):\n",
        "  selected=x[0]\n",
        "  spelling=x[1]\n",
        "  selected=selected.split()\n",
        "  selected.remove(spelling) \n",
        "  return \" \".join(selected)\n",
        "\n",
        "def matching_55(x):\n",
        "  text=x[0]\n",
        "  selected=x[1]\n",
        "  spelling=x[2]\n",
        "  text=text.split()\n",
        "  selected=selected.split()\n",
        "  spelling=spelling.split()\n",
        "  for s in spelling:\n",
        "    for t in text:\n",
        "      if s in selected:\n",
        "        if(fuzz.ratio(t,s)>55): \n",
        "          index=selected.index(s)\n",
        "          selected[index]=t\n",
        "  return \" \".join(selected) \n",
        "\n",
        "def matching_35(x):\n",
        "  text=x[0]\n",
        "  selected=x[1]\n",
        "  spelling=x[2]\n",
        "  text=text.split()\n",
        "  selected=selected.split()\n",
        "  spelling=spelling.split()\n",
        "  for s in spelling:\n",
        "    for t in text:\n",
        "      if s in selected:\n",
        "        if(fuzz.ratio(t,s)>35):\n",
        "          index=selected.index(s)\n",
        "          selected[index]=t\n",
        "  return \" \".join(selected)\n",
        "\n",
        "def start_index(x):\n",
        "  text=x[0]\n",
        "  selected=x[1]\n",
        "  text=text.split()\n",
        "  selected=selected.split()\n",
        "  word=selected[0]\n",
        "  index=text.index(word)\n",
        "  return index\n",
        "\n",
        "def end_index(x):\n",
        "  text=x[0]\n",
        "  selected=x[1]\n",
        "  start_index=x[2] \n",
        "  text=text.split()\n",
        "  selected= selected.split()\n",
        "  word=selected[-1]\n",
        "  try:\n",
        "    index=text.index(word,start_index)\n",
        "  except:\n",
        "    index=text.index(word)\n",
        "  return index\n",
        "\n",
        "def get_text(x):\n",
        "  pred=[]\n",
        "  text=x[0]\n",
        "  index=x[1]\n",
        "  text=text.split()\n",
        "  l=len(text)\n",
        "  # nothing output = output all\n",
        "  if len(index) == 0:\n",
        "    pred = text\n",
        "  for i in index:\n",
        "    if i < l:\n",
        "      pred.append(text[i])\n",
        "  return pred\n",
        "\n",
        "def jaccard(str1,str2): \n",
        "  a=set(str1.lower().split()) \n",
        "  b=set(str2.lower().split())\n",
        "  c=a.intersection(b)\n",
        "\n",
        "  return float(len(c)) / (len(a) + len(b) - len(c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNyZ85hjJBS-"
      },
      "outputs": [],
      "source": [
        "data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRIjcXn4j1_F"
      },
      "outputs": [],
      "source": [
        "# lower case\n",
        "data['text']= data['text'].apply(lambda x: x.lower() if type(x) == str else x)\n",
        "data['selected_text']= data['selected_text'].apply(lambda x: x.lower() if type(x) == str else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hK-gQvElb1x"
      },
      "outputs": [],
      "source": [
        "# remove hyperlink\n",
        "data['text']=data['text'].apply(lambda x:remove_hyperlinks(x) if type(x) == str else x)\n",
        "data['selected_text']=data['selected_text'].apply(lambda x:remove_hyperlinks(x) if type(x) == str else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "475q9p7DmnaK"
      },
      "outputs": [],
      "source": [
        "#\n",
        "data['text']=data['text'].apply(lambda x:remove(x) if type(x) == str else x)\n",
        "data['selected_text']=data['selected_text'].apply(lambda x:remove(x) if type(x) == str else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03OZxA-HnMxV"
      },
      "outputs": [],
      "source": [
        "data['text']=data['text'].apply(lambda x:remove_punctuation(x) if type(x) == str else x)\n",
        "data['selected_text']=data['selected_text'].apply(lambda x:remove_punctuation(x) if type(x) == str else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l9LYcuJJXej"
      },
      "outputs": [],
      "source": [
        "data.drop(data[data[\"text\"]==' '].index,inplace=True)\n",
        "data.drop(data[data[\"selected_text\"]==' '].index,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRFf0wHOnri4"
      },
      "outputs": [],
      "source": [
        "data['spelling']=data.apply(lambda x: wrong_words(x.text,x.selected_text),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2dswJMusLOK"
      },
      "outputs": [],
      "source": [
        "data['selected_text']=data[['selected_text','spelling']].apply(lambda x: remove_text(x) if len(x['spelling'])==1  else x['selected_text'],axis=1)\n",
        "data['spelling']=data.apply(lambda x: wrong_words(x.text,x.selected_text),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejyw14Y_KNv3"
      },
      "outputs": [],
      "source": [
        "data['selected_text']=data.apply(lambda x: x['text'] if ( (x['spelling']!='++++') & (x['sentiment']=='neutral') ) else x['selected_text'],axis=1)\n",
        "data['spelling']=data.apply(lambda x: wrong_words(x.text,x.selected_text),axis=1)\n",
        "# data.loc[(data['spelling']!='++++') & (data['sentiment']=='neutral')].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiAqfWBoukxi"
      },
      "outputs": [],
      "source": [
        "data['selected_text']=data[['text','selected_text','spelling']].apply(lambda x: matching_55(x) if x['spelling']!='++++'  else x['selected_text'],axis=1)\n",
        "data['spelling']=data.apply(lambda x: wrong_words(x.text,x.selected_text),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vton3IoJK-WJ"
      },
      "outputs": [],
      "source": [
        "data['selected_text']=data[['selected_text','spelling']].apply(lambda x: remove_text(x) if len(x['spelling'])==1  else x['selected_text'],axis=1)\n",
        "data['spelling']=data.apply(lambda x: wrong_words(x.text,x.selected_text),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eegRhR7_Mh2P"
      },
      "outputs": [],
      "source": [
        "data['selected_text']=data[['text','selected_text','spelling']].apply(lambda x: matching_35(x) if x['spelling']!='++++'  else x['selected_text'],axis=1)\n",
        "data['spelling']=data.apply(lambda x: wrong_words(x.text,x.selected_text),axis=1)\n",
        "# data.loc[(data['spelling']!='++++') & (data['sentiment']=='positive')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "EDmEPKdJPqW5",
        "outputId": "3151dd5c-528d-4cf3-a613-ba8ba357c4fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9be06c1d-d857-4412-8edd-d490c3df1494\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>spelling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9be06c1d-d857-4412-8edd-d490c3df1494')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9be06c1d-d857-4412-8edd-d490c3df1494 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9be06c1d-d857-4412-8edd-d490c3df1494');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [textID, text, selected_text, sentiment, spelling]\n",
              "Index: []"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# negative\n",
        "data.loc[2398].selected_text='did miss you'\n",
        "data.loc[6113].selected_text='these dogs are going to die if somebody doesnt save them'\n",
        "data.loc[9817].text='following and followers not nice'\n",
        "data.loc[13637].selected_text='hates me  cryyyy'\n",
        "data.loc[14839].selected_text='boring but had to eat nonetheless'\n",
        "data.loc[16201].selected_text='off to work'\n",
        "data.loc[25293].selected_text='at the bottom of the totem pole'\n",
        "\n",
        "# positive\n",
        "data.loc[1588].selected_text='woooooooooo'\n",
        "data.loc[10521].selected_text='greetings'\n",
        "data.loc[7410].text='im in the room im watching the hannah movie with mom she said this film very great'\n",
        "\n",
        "data['spelling']=data.apply(lambda x: wrong_words(x.text,x.selected_text),axis=1)\n",
        "\n",
        "data[data['spelling'].apply(lambda x: len(x))==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kkCmIiNO79F"
      },
      "outputs": [],
      "source": [
        "data.reset_index(inplace=True)\n",
        "data.drop(['index'],inplace=True,axis=1)\n",
        "\n",
        "# drop text & selected_text ==''\n",
        "data.drop(8727,inplace=True)\n",
        "data.drop(25996,inplace=True)\n",
        "\n",
        "data.reset_index(inplace=True)\n",
        "data.drop(['index'],inplace=True,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKUBToSLIDbe",
        "outputId": "5d1295f2-6944-4d40-b13a-d6867eb6bf37"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ],
      "source": [
        "data['start_index']=data[['text','selected_text']].apply(lambda x: start_index(x),axis=1)\n",
        "data['end_index']=data[['text','selected_text','start_index']].apply(lambda x: end_index(x),axis=1)\n",
        "\n",
        "data= data[data.start_index <= data.end_index]\n",
        "\n",
        "data.reset_index(inplace=True)\n",
        "data.drop(['index'],inplace=True,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vENfX0LHPy0-",
        "outputId": "88c72a62-3c58-416e-bee2-0a7bd33054ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(27381, 7)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVhLT3HnrvRA"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# data.to_csv('output.csv', encoding = 'utf-8-sig') \n",
        "# files.download('output.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdlM6n95VMCx"
      },
      "source": [
        "# **3.Sentiment Analysis using LSTM & Bi-LSTM**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE3qZD6yVOWZ"
      },
      "source": [
        "###**import** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYVYxMNNRDZD",
        "outputId": "35f6235c-b9d4-46eb-c160-483b8c0b5445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "## Training part\n",
        "import tensorflow as tf\n",
        "!pip install --upgrade tensorflow\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X48a4mytqE6i"
      },
      "source": [
        "### **Splitting dataset & Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ij_7PCwlxnf"
      },
      "outputs": [],
      "source": [
        "def one_hot_coding(raw_data, max_len_text):\n",
        "    # Get X, y for training\n",
        "    X=raw_data[['textID','text','selected_text','sentiment']]\n",
        "\n",
        "    y=np.zeros((raw_data.shape[0],max_len_text+1))\n",
        "    for i in range(raw_data.shape[0]):\n",
        "      start=raw_data['start_index'][i]\n",
        "      end=raw_data['end_index'][i]\n",
        "      y[i][start:end+1]=1\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdlbvllosrqa"
      },
      "outputs": [],
      "source": [
        "# splitting data into train &test dataset\n",
        "train = data.sample(frac=0.85, random_state=200)\n",
        "test = data.merge(train, how='left', indicator=True)\n",
        "test = test[test['_merge'] == 'left_only']\n",
        "\n",
        "train.reset_index(inplace = True)\n",
        "test.reset_index(inplace = True)\n",
        "\n",
        "text_split=data['text'].apply(lambda x: len(str(x).split())).tolist()\n",
        "max_len_text = max(text_split)\n",
        "\n",
        "# X_train.shape (23274, 4), X_test.shape (4107, 4)\n",
        "# y_train.shape (23274, 33), y_test.shape (4107, 33)\n",
        "X_train, y_train = one_hot_coding(train, max_len_text)\n",
        "X_test, y_test = one_hot_coding(test, max_len_text)\n",
        "# X_test = X_test[['textID','text','sentiment']]\n",
        "\n",
        "# Split into training data & validation data\n",
        "## X_train shape  (21877, 4)  , X_valid shape  (1397, 4)\n",
        "## y_train shape  (21877, 33) ,  y_valid shape  (1397, 33)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.06, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E7iNouwoIoc"
      },
      "outputs": [],
      "source": [
        "# Add dims (y shape)\n",
        "y_train=np.expand_dims(y_train,-1)\n",
        "y_valid=np.expand_dims(y_valid,-1)\n",
        "# transfer text & sentiment into list of strings\n",
        "train_text=X_train['text'].values\n",
        "valid_text=X_valid['text'].values\n",
        "train_sentiment=X_train['sentiment'].values\n",
        "valid_sentiment=X_valid['sentiment'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe5oiFtpwuNl"
      },
      "outputs": [],
      "source": [
        "# Keras tokenizer( text)\n",
        "token1= tf.keras.preprocessing.text.Tokenizer(num_words=None)\n",
        "\n",
        "token1.fit_on_texts(list(train_text))\n",
        "train_text=token1.texts_to_sequences(train_text)\n",
        "valid_text=token1.texts_to_sequences(valid_text)\n",
        "\n",
        "# Keras tokenizer( sentiment)\n",
        "token2= tf.keras.preprocessing.text.Tokenizer(num_words=None)\n",
        "\n",
        "token2.fit_on_texts(list(train_sentiment))\n",
        "train_sentiment=token2.texts_to_sequences(train_sentiment)\n",
        "valid_sentiment=token2.texts_to_sequences(valid_sentiment)\n",
        "\n",
        "# Pads each sequence to the same length\n",
        "max_len_text=32\n",
        "train_text= tf.keras.preprocessing.sequence.pad_sequences(train_text,maxlen=max_len_text,padding='post')\n",
        "valid_text= tf.keras.preprocessing.sequence.pad_sequences(valid_text,maxlen=max_len_text,padding='post')\n",
        "max_len_sentiment=1\n",
        "train_sentiment= tf.keras.preprocessing.sequence.pad_sequences(train_sentiment,maxlen=max_len_sentiment,padding='post')\n",
        "valid_sentiment= tf.keras.preprocessing.sequence.pad_sequences(valid_sentiment,maxlen=max_len_sentiment,padding='post')\n",
        "\n",
        "word_index_text=token1.word_index\n",
        "word_index_sentiment=token2.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zKctezhlzip"
      },
      "outputs": [],
      "source": [
        "# test data\n",
        "test_text = test['text'].values\n",
        "test_sentiment = test['sentiment'].values\n",
        "\n",
        "test_text=token1.texts_to_sequences(test_text)\n",
        "test_text=tf.keras.preprocessing.sequence.pad_sequences(test_text,maxlen=max_len_text,padding='post')\n",
        "\n",
        "test_sentiment=token2.texts_to_sequences(test_sentiment)\n",
        "test_sentiment=tf.keras.preprocessing.sequence.pad_sequences(test_sentiment,maxlen=max_len_sentiment,padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_Dr4vu0qTf_"
      },
      "source": [
        "### **Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMBoH9MJ3D2B",
        "outputId": "f19ccbc2-16cb-48c2-f613-8dbdf8e733b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2196017it [04:24, 8295.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2196016 word vectors.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# load the GloVe vectors in a dictionary:\n",
        "embeddings_index = {}\n",
        "with open('/content/glove.840B.300d.txt') as f:\n",
        "  for line in tqdm(f):\n",
        "    values = line.split(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray([float(val) for val in values[1:]])\n",
        "    embeddings_index[word] = coefs\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3fRleri7E6V"
      },
      "outputs": [],
      "source": [
        "# Use pre-trained word embedding \n",
        "# create  an embedding matrix for text\n",
        "embedding_matrix_text=np.zeros((len(word_index_text) + 1, 300))\n",
        "for word, i in word_index_text.items():\n",
        "    embedding_vector=embeddings_index.get(word)\n",
        "    if embedding_vector is not None: # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix_text[i]=embedding_vector\n",
        " \n",
        "# create  an embedding matrix for sentiment\n",
        "embedding_matrix_sentiment=np.zeros((len(word_index_sentiment) + 1, 300))\n",
        "for word, i in word_index_sentiment.items():\n",
        "    embedding_vector=embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_sentiment[i]=embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXTU9m7fWGYk"
      },
      "source": [
        "## **3.1 LSTM architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8tUsTxb1iWA"
      },
      "outputs": [],
      "source": [
        "# LSTM model part\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import jaccard_score\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.regularizers import l2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVUFHhUK9DeW"
      },
      "outputs": [],
      "source": [
        "text_input=layers.Input(shape=(max_len_text,))\n",
        "text_embedding = layers.Embedding(\n",
        "    len(word_index_text)+1,\n",
        "    300,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix_text),\n",
        "    mask_zero=True,\n",
        "    trainable=False,\n",
        "    input_length=max_len_text)(text_input)\n",
        "sentiment_input=layers.Input(shape=(max_len_sentiment,))\n",
        "sentiment_embedding = layers.Embedding(\n",
        "    len(word_index_sentiment)+1,\n",
        "    300,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix_sentiment),\n",
        "    mask_zero=True,\n",
        "    trainable=False,\n",
        "    input_length=max_len_sentiment)(sentiment_input)\n",
        "con=layers.Concatenate(axis=1)([text_embedding,sentiment_embedding])\n",
        "lstm=LSTM(32,return_sequences=True)(con) #lstm\n",
        "\n",
        "d = layers.Dense(16,activation=\"relu\")(lstm)\n",
        "d = layers.Dropout(0.5)(d)\n",
        "d = layers.BatchNormalization()(d)\n",
        "d = layers.Dense(4,activation=\"relu\")(d)\n",
        "output=layers.Dense(1,activation='sigmoid')(d)\n",
        "\n",
        "model1=keras.Model(inputs=[text_input,sentiment_input],outputs=[output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d_tUAOzluTH",
        "outputId": "30befcaa-b1b7-4835-f2dd-8aa66fd81f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "171/171 [==============================] - 42s 201ms/step - loss: 0.2262 - accuracy: 0.6956 - val_loss: 0.2362 - val_accuracy: 0.6379\n",
            "Epoch 2/30\n",
            "171/171 [==============================] - 29s 169ms/step - loss: 0.2225 - accuracy: 0.7031 - val_loss: 0.2383 - val_accuracy: 0.6399\n",
            "Epoch 3/30\n",
            "171/171 [==============================] - 29s 167ms/step - loss: 0.2204 - accuracy: 0.7072 - val_loss: 0.2370 - val_accuracy: 0.6343\n",
            "Epoch 4/30\n",
            "171/171 [==============================] - 29s 172ms/step - loss: 0.2175 - accuracy: 0.7118 - val_loss: 0.2394 - val_accuracy: 0.6392\n",
            "Epoch 5/30\n",
            "171/171 [==============================] - 28s 166ms/step - loss: 0.2147 - accuracy: 0.7187 - val_loss: 0.2405 - val_accuracy: 0.6349\n",
            "Epoch 6/30\n",
            "171/171 [==============================] - 28s 166ms/step - loss: 0.2120 - accuracy: 0.7224 - val_loss: 0.2476 - val_accuracy: 0.6370\n",
            "Epoch 7/30\n",
            "171/171 [==============================] - 29s 167ms/step - loss: 0.2090 - accuracy: 0.7283 - val_loss: 0.2483 - val_accuracy: 0.6365\n",
            "Epoch 8/30\n",
            "171/171 [==============================] - 30s 174ms/step - loss: 0.2065 - accuracy: 0.7330 - val_loss: 0.2523 - val_accuracy: 0.6325\n",
            "Epoch 9/30\n",
            "171/171 [==============================] - 29s 169ms/step - loss: 0.2040 - accuracy: 0.7371 - val_loss: 0.2515 - val_accuracy: 0.6344\n",
            "Epoch 10/30\n",
            "171/171 [==============================] - 29s 168ms/step - loss: 0.2033 - accuracy: 0.7381 - val_loss: 0.2549 - val_accuracy: 0.6393\n",
            "Epoch 11/30\n",
            "171/171 [==============================] - 30s 173ms/step - loss: 0.1997 - accuracy: 0.7445 - val_loss: 0.2512 - val_accuracy: 0.6317\n",
            "Epoch 12/30\n",
            "171/171 [==============================] - 30s 173ms/step - loss: 0.1966 - accuracy: 0.7487 - val_loss: 0.2624 - val_accuracy: 0.6333\n",
            "Epoch 13/30\n",
            "171/171 [==============================] - 29s 168ms/step - loss: 0.1937 - accuracy: 0.7527 - val_loss: 0.2687 - val_accuracy: 0.6317\n",
            "Epoch 14/30\n",
            "171/171 [==============================] - 28s 165ms/step - loss: 0.1912 - accuracy: 0.7576 - val_loss: 0.2612 - val_accuracy: 0.6301\n",
            "Epoch 15/30\n",
            "171/171 [==============================] - 28s 166ms/step - loss: 0.1904 - accuracy: 0.7592 - val_loss: 0.2618 - val_accuracy: 0.6203\n",
            "Epoch 16/30\n",
            "171/171 [==============================] - 28s 161ms/step - loss: 0.1876 - accuracy: 0.7628 - val_loss: 0.2680 - val_accuracy: 0.6349\n",
            "Epoch 17/30\n",
            "171/171 [==============================] - 28s 163ms/step - loss: 0.1859 - accuracy: 0.7653 - val_loss: 0.2693 - val_accuracy: 0.6325\n",
            "Epoch 18/30\n",
            "171/171 [==============================] - 28s 166ms/step - loss: 0.1837 - accuracy: 0.7688 - val_loss: 0.2699 - val_accuracy: 0.6281\n",
            "Epoch 19/30\n",
            "171/171 [==============================] - 28s 165ms/step - loss: 0.1806 - accuracy: 0.7735 - val_loss: 0.2809 - val_accuracy: 0.6307\n",
            "Epoch 20/30\n",
            "171/171 [==============================] - 28s 162ms/step - loss: 0.1794 - accuracy: 0.7744 - val_loss: 0.2686 - val_accuracy: 0.6257\n",
            "Epoch 21/30\n",
            "171/171 [==============================] - 28s 164ms/step - loss: 0.1783 - accuracy: 0.7778 - val_loss: 0.2828 - val_accuracy: 0.6183\n",
            "Epoch 22/30\n",
            "171/171 [==============================] - 28s 164ms/step - loss: 0.1749 - accuracy: 0.7824 - val_loss: 0.2809 - val_accuracy: 0.6325\n",
            "Epoch 23/30\n",
            "171/171 [==============================] - 28s 162ms/step - loss: 0.1746 - accuracy: 0.7814 - val_loss: 0.2747 - val_accuracy: 0.6218\n",
            "Epoch 24/30\n",
            "171/171 [==============================] - 28s 163ms/step - loss: 0.1724 - accuracy: 0.7855 - val_loss: 0.2843 - val_accuracy: 0.6226\n",
            "Epoch 25/30\n",
            "171/171 [==============================] - 27s 160ms/step - loss: 0.1708 - accuracy: 0.7882 - val_loss: 0.2813 - val_accuracy: 0.6332\n",
            "Epoch 26/30\n",
            "171/171 [==============================] - 28s 162ms/step - loss: 0.1702 - accuracy: 0.7899 - val_loss: 0.2838 - val_accuracy: 0.6291\n",
            "Epoch 27/30\n",
            "171/171 [==============================] - 28s 163ms/step - loss: 0.1676 - accuracy: 0.7933 - val_loss: 0.2824 - val_accuracy: 0.6265\n",
            "Epoch 28/30\n",
            "171/171 [==============================] - 28s 162ms/step - loss: 0.1667 - accuracy: 0.7937 - val_loss: 0.2837 - val_accuracy: 0.6310\n",
            "Epoch 29/30\n",
            "171/171 [==============================] - 28s 163ms/step - loss: 0.1652 - accuracy: 0.7959 - val_loss: 0.3014 - val_accuracy: 0.6290\n",
            "Epoch 30/30\n",
            "171/171 [==============================] - 28s 165ms/step - loss: 0.1638 - accuracy: 0.7970 - val_loss: 0.2890 - val_accuracy: 0.6252\n"
          ]
        }
      ],
      "source": [
        "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "optim = keras.optimizers.Adam(lr=0.001)\n",
        "metrics = [\"accuracy\"]\n",
        "\n",
        "model1.compile(loss=loss, optimizer=optim, metrics=metrics)\n",
        "\n",
        "history=model1.fit([train_text,train_sentiment],y_train,epochs=30,batch_size=128,\\\n",
        "                  validation_data=([valid_text,valid_sentiment],y_valid),verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFoADxCHyUYd"
      },
      "source": [
        "Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "7qEl9iOLCfIv",
        "outputId": "93f6dd72-c20a-43f8-b8ac-3bdc54034f24"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAEGCAYAAAAQSF6jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhV1bn48e+bmRAykEAIJEwKMk9BBnEAFYsToKLirFVpHau2/dXe22sd6q3ttdbaWltqcVZEVKQVREXiUAHDPIQpjAkzgQSSkPn9/bFOIByTcIAcTpLzfp7nPDl777VX1sqBvFnjFlXFGGOMMUeFBLoAxhhjTGNjwdEYY4zxYsHRGGOM8WLB0RhjjPFiwdEYY4zxEhboApwOSUlJ2rlz51POp6ioiJYtW556gZoQq3NwsDoHj2Csd211Xrx48T5VbVPXPUERHDt37syiRYtOOZ+MjAxGjhx56gVqQqzOwcHqHDyCsd611VlEttZ3j3WrGmOMMV4sOBpjjDFe/BocRWSMiKwTkWwRebSW6x1FZJ6ILBWRFSJyWY1rv/Tct05EfuBrnsYYY8yp8tuYo4iEAi8Co4FcIFNEZqpqVo1kvwKmqepLItILmAV09ryfCPQG2gOfi0h3zz3Hy9Mn5eXl5ObmUlJS4vM9cXFxrFmz5kS/VZPma52joqJITU0lPDz8NJTKGGP8y58TcoYA2aq6CUBEpgLjgJqBTIFYz/s4YIfn/ThgqqqWAptFJNuTHz7k6ZPc3FxatWpF586dERGf7jl06BCtWrU60W/VpPlSZ1UlLy+P3NxcunTpcppKZowx/uPP4NgByKlxnAsM9UrzOPCpiDwAtAQurnHvAq97O3jeHy9PAERkEjAJIDk5mYyMjGOux8XFkZiYSGFhoW+1ASorKzl06JDP6ZsDX+scERFBfn7+937OTVFhYWGzqMeJsDoHj2Cs98nUOdBLOW4AXlXVP4jIcOANEenTEBmr6mRgMsDgwYPVexrvmjVriI2NreXOulnLsX5RUVEMHDjQzyXyP5vqHhyCsc4QnPU+mTr7MzhuB9JqHKd6ztV0JzAGQFXni0gUkHSce4+XpzHGmGZAVckvLmfXwRJ2HSxhd4H7OuqstvRPi/fr9/ZncMwEuolIF1wAmwjc6JVmG3AR8KqI9ASigL3ATOBtEXkONyGnG/AdID7k2STk5+fz9ttvc++9957QfZdddhlvv/028fH+/YdhjDH+dqiknPW7C9nlCXq7D5Yceb+rwB2XVlR9777WLSOabnBU1QoRuR+YA4QCU1R1tYg8CSxS1ZnAT4F/iMjDuMk5t6t7+vJqEZmGm2hTAdynqpUAteXprzr4U35+Pn/961+/FxwrKioIC6v7Y5k1a5a/i2aMMQ0ur7CU1TsOsmpHAat3HGT19gK25BUfkyYiLIR2sVG0i4tiQFo87eKiSI6N8pyLJDk2iratoogI8/8Sfb+OOarqLNzyjJrnHqvxPgsYUce9TwNP+5JnU/Too4+yceNGBgwYQHh4OFFRUSQkJLB27VrWr1/P+PHjycnJoaSkhJ/85CdMmjQJOLoVXmFhIZdeeinnnnsu3377LR06dOCjjz6iRYsWAa6ZMSaYqSo7C0pcINzuCYQ7CthZcHTZXFrrFvROiWNCeio9U2JpH9+CdrFRxEeH+7x6wN8CPSGnUXjiX6vJ2nHwuOkqKysJDQ31Kc9e7WP59ZW967z+zDPPsGrVKpYtW0ZGRgaXX345q1atOrIUYsqUKbRu3ZrDhw9z9tlnc80115CYmHhMHhs2bOCdd97hH//4B9dddx3vv/8+N998s0/lM8aY+lRUVrE0J59tecUcLq/kcFklh8srKS6rpMRzXHzkfIU7Lqtkz6FS9heVARAi0LVNDEO7tKZ3+zh6d4ild0occdGNfz20BcdGYsiQIcesEXzhhRf48MMPAcjJyWHDhg3fC45dunRhwIABAKSnp7Nly5bTVl5jTPNTXFbBV+v38VnWbr5Yu5sDxeXfSxMRGkJUeAjREWG0iAglKjyU6IhQoiPCSIyJZEBaPL3bx9KrfRw9U1oRHdE0w0zTLHUDq6+FV5M/l3LUfJxKRkYGn3/+OfPnzyc6OpqRI0fWupNPZGTkkfehoaEcPnzYL2UzxjRfew6VMHfNHj7L2s032fsoq6giNiqMC3u0ZXSvdvRuH0t0ROiRQBgeGhxbcltwDJBWrVrVubi+oKCAhIQEoqOjWbt2LQsWLKg1nTHGnChVJXvPIT7N2s1nWbtZlpOPKqQmtOCmoR0Z3SuZszu3DpogWBcLjgGSmJjIiBEj6NOnDy1atCA5OfnItTFjxvC3v/2Nnj17ctZZZzFs2LAAltQY01SpKvsKy9i0t5BN+4pYv/sQs5YeZvecrwDo2yGOhy/uzuheyfRo16rRTIZpDCw4BtDbb79d6/nIyEhmz55d67XqccWkpCRWrVp15PzPfvazBi+fMaZpKCmvZPO+IjbvK3KBcG8RGz3vD5VUHEkXGRZCt7gQ7h/dg4t7JZMSZ7Pb62LB0RhjmpDDZZUs3XaA77bsZ+m2fLL3FLKj4DCqR9OkxEXRtU1Lxg/oQNc2LenaJoauSS3pEN+Cr776kpHDOwes/E2FBUdjjGnECorLWbR1P99t2c93m/ezMreAiipFBM5KbkV6pwSubZN6JAB2bdOyyc4QbUzsJ2iMMY3InoMlfLdlP5mb97Nw837W7T6EKoSHCv1T47n7/K4M6dKa9E4JxEY1/vWCTZUFR2OMCbA1Ow/y/uJcPl+z+8iWatERoaR3SuCyvikM6dKaAWnxRIX7tgmJOXUWHI0xJgDyCkv5aNkO3l+Sy+odBwkPFc7r1oabhnZiSJfW9GofG/TLKQLJgqMxxpwmZRVVzFu3h/cX5/LF2j1UVCl9O8TxxNjeXNm/Pa1bRgS6iMbD/ixpImJiYgDYsWMHEyZMqDXNyJEjWbRoUb35PP/88xQXH90J/7LLLiM/P7/hCmpMM1RVpXy3eT8LNuWxcW8hBYfL0ZrTQ+uhqqzaXsDjM1cz7Ldz+dEbi1myLZ8fntuFOQ+dz78eOJfbzulsgbGRsZZjE9O+fXumT59+0vc///zz3HzzzURHRwP2CCxj6nOgqIz3Fufw5oJtbNv//ccrtYmJJKlVJG1iImjTKpKkmMgjX5NiIlmRm8/0xbms3XWIiNAQRvdK5pr0DpzfrQ1h1mXaqFlwDJBHH32UtLQ07rvvPgAef/xxwsLCmDdvHgcOHKC8vJzf/OY3jBs37pj7tmzZwhVXXMGqVas4fPgwd9xxB8uXL6dHjx7H7K16zz33kJmZyeHDh5kwYQJPPPEEL7zwAjt27GDUqFEkJSUxb968I4/ASkpK4rnnnmPKlCkA3HXXXTz00ENs3bqVa6+91h6NZYLKitx8Xp+/lX8t30FpRRVDOrfmp5d0Jykmkr2HStl7qJR9he7r3sJScg8cZllOAXlFpXg3KPunxfPUONdtGh9trcOmwoIjwOxHYdfK4yZrUVkBoT7+yNr1hUufqfPy9ddfz0MPPXQkOE6bNo05c+bw4IMPEhsby759+xg2bBhjx46tc0unl156iejoaNasWcOKFSsYNGjQkWtPP/00rVu3prKykosuuogVK1bw4IMP8txzzzFv3jySkpKOyWvx4sW88sorLFy4EFVl6NChXHDBBYSHh9ujsUxQKCmv5N8rdvLGgq0sz8knOiKUCemp3DK8Ez3axfqUR2WVsr+o7EjQ7BAfxZlt/fOwAuNfFhwDZODAgezZs4cdO3awd+9eEhISaNeuHQ8//DBfffUVISEhbN++nd27d9OuXbta8/jqq6948MEHAejXrx/9+vU7cm3atGlMnjyZiooKdu7cSVZW1jHXvX3zzTdcddVVR54OcvXVV/P1119z4YUX2qOxTLOWs7+YNxduZVpmDgeKyzmjTUsev7IXV6ennvA6wtAQoU0r17VqmjYLjlBvC6+mww38yKprr72W6dOns2vXLq6//nreeust9u7dy+LFiwkPD6dz5861PqrqeDZv3syzzz5LZmYmCQkJ3H777SeVTzV7NJZpbioqq1ixt4I3Xs3ki3V7CBFhdM9kbhneiXPOSLQNuI1/Z6uKyBgRWSci2SLyaC3X/ygiyzyv9SKS7zk/qsb5ZSJSIiLjPddeFZHNNa4N8Gcd/On6669n6tSpTJ8+nWuvvZaCggLatm1LeHg48+bNY+vWrfXef/755x/ZvHzVqlWsWLECgIMHD9KyZUvi4uLYvXv3MZuY1/WorPPOO48ZM2ZQXFxMUVERH374Ieedd14D1taYwCosrWDWyp08/O4y0n/zOc8tLmV5bgH3jzqTb34xir/dks6IM5MsMBrAjy1HEQkFXgRGA7lApojMVNWs6jSq+nCN9A8AAz3n5wEDPOdbA9nApzWy/7mqnvyUzUaid+/eHDp0iA4dOpCSksJNN93ElVdeSd++fRk8eDA9evSo9/577rmHO+64g549e9KzZ0/S09MB6N+/PwMHDqRHjx6kpaUxYsSII/dMmjSJMWPG0L59e+bNm3fk/KBBg7j99tsZMmQI4CbkDBw48JgnfxjT1OwqKOGzNbv5PGs38zfmUVZZRUJ0OBf3TKa97uWBay4kIsxmjZrv82e36hAgW1U3AYjIVGAckFVH+huAX9dyfgIwW1WLa7nW5K1ceXQiUFJSEvPnz681XWFhIQCdO3c+ErBatGjB1KlTa03/6quv1nr+gQce4IEHHjhyXHP88JFHHuGRRx45Jn2nTp3s0VimyVBV1u46xGdZu/l8zW5W5BYA0DkxmtvO6cTFPZNJ75RAWGgIGRkZFhhNnfwZHDsAOTWOc4GhtSUUkU5AF+CLWi5PBJ7zOve0iDwGzAUeVdXSUy+uMaYpUFUKSyvYX1RGXlEZeYVl7C8qZc3OQ3y+Zje5Bw4jAgPS4vl/Y85idM9kzmwbY92l5oSIr7s8nHDGIhOAMap6l+f4FmCoqt5fS9pfAKmq+oDX+RRgBdBeVctrnNsFRACTgY2q+mQteU4CJgEkJyene7ew4uLiOPPMM0+oTpWVlYSGBtfGvydS5+zsbAoKCvxcIv8rLCw8siNRsGhMda5SJSuvkq0HqzhYphwqw/PVvQ6WKRVV378vPAR6JYYyqG0o/duGEh9Zf6uwMdX5dArGetdW51GjRi1W1cF13ePPluN2IK3GcarnXG0mAvfVcv464MPqwAigqjs9b0tF5BWg1n4+VZ2MC54MHjxYR44cecz1NWvWEBNzYn9NHmrg2apNga91VlWioqIYOHDgaSiVf2VkZOD976W5awx1Ligu9+xGs5Utea4zqEV4KK1bRpAUE0HXxAgSYyJJbBlBYkwErVvWfO92qIkM8/2P18ZQ50AIxnqfTJ39GRwzgW4i0gUXFCcCN3onEpEeQAJQ22DbDcAvvdKnqOpOcVFtPHBSM0aioqLIy8sjMdGmbZ8qVSUvL4+oqKhAF8U0QVk7DvLGgi18uHQ7JeVVDO6UwMOju3Nxz2RaRtpqMxMYfvuXp6oVInI/MAcIBaao6moReRJYpKozPUknAlPVq39XRDrjWp5femX9loi0AQRYBvz4ZMqXmppKbm4ue/fu9fmekpKSoAsAvtY5KiqK1NTU01Ai0xyUVVTxyepdvP7tFhZtPUBUeAjjB3TgluGd6N0+LtDFM8a/mwCo6ixglte5x7yOH6/j3i24ST3e5y9siLKFh4fTpUuXE7onIyOjWXQbnohgrLPxn90HS3hr4Tbe+W4bew+V0rF1NL+6vCfXpqcRF21PtTeNh/VZGGP8qrJKWbg5j7cWbGPO6l1UqjKyextuPaczF3RrQ0iIDWuYxseCozGmwZWUV/Kf7H3MWb2Lz9fsYX9RGbFRYdwxojM3D+tEp8SWgS6iMfWy4GiMaRAHS8qZt3YPn67eTca6PRSVVRITGcaoHm35Qe9kLuqRTIuI4FoKZZouC47GmJO252AJn2bt5tOs3czfuI/ySiUpJpKxAzrwg97JDD8j8YSWVxjTWFhwNMb4rLSiktU7DvLd5v18unoXS3PyUYVOidHcMaILP+idzMC0BBtHNE2eBUdjTJ12HyxhydYDLNl2gCXb8lm5vYAyz/Y0fTrE8sjF3bmkdzu6J9v2bKZ5seBojAHc2sOsnQePBMOl2/LZnu+e3RkRFkLfDnHcNrwTgzomMKhTAsmxwbXm1wQXC47GBLHsPYXMXrmTfy06zNbP51DqaRW2j4tiYKcEfnhuFwZ1jKdX+1gbOzRBxYKjMUFEVVm/u5BZK3cye9VO1u92j0LrEhfCzcOqW4XxpMS1CHBJjQksC47GNHOqyuodB5m9aiezV+5i074iRGBI59Y8MbY3P+jdjrVLFzByZK9AF9WYRsOCozHNkKqyPLfgSEDctr+Y0BBhWNfW/PDcLlzSO5m2rY6OGa4NYFmNaYwsOBrTxBWVVrAlr4gt+4o9X4v4dmMe2/MPExYijDgziftGncHoXu1o3TIi0MU1pkmw4GhME1BYWsFWrwC4Ja+ILXnF7D1Uekzatq0i6Zcax8OjuzO6Z7Jt6G3MSbDgaEwjdbCknHe/y+GthVvZkld8zLW2rSLpnNiSUWe1oXNSSzonulenxGh7BqIxDcD+FxnTyOTsL2bKfzYzLTOHorJKhnRpzXVnp1kANOY0sv9hxjQCqsrirQf45zebmbN6FyEiXNEvhTvP7UrfVHv4rzGnmwVHYwKovLKK2at28c9vNrM8J5+4FuH86IIzuG14Z9rF2Q40xgSKBUdjAqDgcDnvZm7j1f9sYUdBCZ0To3lqXG+uSU8lOsL+WxoTaPa/0JjTKGvHQaYtyuG9RW48cVjX1jw5rg8X9mhrT7IwphHxa3AUkTHAn4BQ4GVVfcbr+h+BUZ7DaKCtqsZ7rlUCKz3XtqnqWM/5LsBUIBFYDNyiqmX+rIcxp2JnwWE+WraDGUu3s3bXIcJDhSv7teeH53ahTwcbTzSmMfJbcBSRUOBFYDSQC2SKyExVzapOo6oP10j/ADCwRhaHVXVALVn/Dvijqk4Vkb8BdwIv+aMOxpyswtIKZq/cyYdLtzN/Ux6qMLBjPE+N683l/drbYnxjGjl/thyHANmquglARKYC44CsOtLfAPy6vgzFPTDuQuBGz6nXgMex4GgagfLKKr7ZsI8Plm7ns6xdlJRX0Skxmgcv7MZVAzvQOalloItojPGRqKp/MhaZAIxR1bs8x7cAQ1X1/lrSdgIWAKmqWuk5VwEsAyqAZ1R1hogkAQtU9UxPmjRgtqr2qSXPScAkgOTk5PSpU6eecp0KCwuJiYk55XyaEqtz/VSVLQer+HZHBQt2VnCoDFqGw9CUMM5JCeOM+JAm8RBg+5yDRzDWu7Y6jxo1arGqDq7rnsYyIWciML06MHp0UtXtItIV+EJEVgIFvmaoqpOByQCDBw/WkSNHnnIhMzIyaIh8mhKrc+32HCrhwyXbmb4klw17iokIC+Hinu0YP6ADI89qS0RYyOkpbAOxzzl4BGO9T6bO/gyO24G0GsepnnO1mQjcV/OEqm73fN0kIhm48cj3gXgRCVPViuPkaUyDKquoYu6a3by3OJcv1++lskpJ75TAb6/uy2V9U4hrYXuYGtNc+DM4ZgLdPLNLt+MC4I3eiUSkB5AAzK9xLgEoVtVST1fqCOD3qqoiMg+YgJuxehvwkR/rYIJc9bMQpy/O5aNl2zlQXE672Ch+dH5XrklP5Yw2wdU9ZUyw8FtwVNUKEbkfmINbyjFFVVeLyJPAIlWd6Uk6EZiqxw5+9gT+LiJVQAhuzLF6Is8vgKki8htgKfBPf9XBBK+8wlJmLNvBe4tyWLvrEBFhIVzSK5kJ6amc160NobYm0Zhmza9jjqo6C5jlde4xr+PHa7nvW6BvHXluws2ENabBfbtxHy8sKWHFp3OpqFL6p8bx1Pg+jO3X3h79ZEwQaSwTcowJqJz9xfzm4yzmrN5NbITww3O7MCE9le7JrQJdNGNMAFhwNEGtuKyClzI28vevNhEWIvz8B2fRrSqHSy7qGeiiGWMCyIKjCUqqyszlO3hm9lp2FpRw1cAO/GJMD9rFRZGRkRvo4hljAsyCowk6q7YX8MS/VpO55QB9O8TxlxsHkt6pdaCLZYxpRCw4mqCRV1jKs5+uY2pmDq2jI/jdNX25Nj3NnoZhjPkeC46m2SuvrOL1+Vt5/vP1HC6r5IcjuvDgRd1s0b4xpk4WHE2zU1JeSV5RGXmFpWzJK+aFuRvI3lPI+d3b8NgVPTmzrc1ANcbUz4KjaTIqKqtYmpPProIS8gpL2VdYRl6R52thqScgllFYWnHMfZ0So3n51sFc1LNtk9gE3BgTeBYcTaO3btch3l+Sy4dLt7P3UOmR8yECrVtGkhQTQWJMBP0T4kmMiSApxnOuZSSJMRH0ah9LZFhoAGtgjGlqLDiaRulAURkzl+9g+uJcVm4vICxEGNWjLVcN7MCZbWNIbBlBfHSEbeNmjPELC46m0SivrOLLdXuZvjiXuWt3U16p9G4fy2NX9GLcgPYkxkQGuojGmCBhwdEE3JqdR596sa+wjKSYCG4d3plrBqXSq31soItnjAlCFhxNQBSVVvDh0u288902Vu84SHiocHHPZK4ZlMoFZ7UhPLRpPSzYGNO8WHA0p9XWvCJen7+VaYtyOFRSQe/2sTwxtjdj+7cnoWVEoItnjDGABUdzGlRVKV9n7+O1b7cwb90eQkW4tG8Kt5/TmUEd4215hTGm0bHgaPzmUEk57y/O5fX5W9m0r4ikmEgeuLAbNw3tSHJsVKCLZ4wxdbLgaBrcxr2FvP7tFqYvzqWorJIBafE8f/0ALuubQkSYjSUaYxo/C46mQagq32TvY/JXm/h6wz4iQkO4ol8Kt53Tmf5p8YEunjHGnBALjuaULdl2gN9/spYFm/aTHBvJT0d3Z+KQjrRpZesSjTFNk1+Do4iMAf4EhAIvq+ozXtf/CIzyHEYDbVU1XkQGAC8BsUAl8LSqvuu551XgAqDAc9/tqrrMn/UwtVu76yDPzlnP52t2kxQTweNX9uKGoR1tqzZjTJPnt+AoIqHAi8BoIBfIFJGZqppVnUZVH66R/gFgoOewGLhVVTeISHtgsYjMUdV8z/Wfq+p0f5Xd1G9bXjHPfbaOj5bvICYyjJ9d0p07RnShZaR1RBhjmofj/jYTkSuBj1W16gTzHgJkq+omTz5TgXFAVh3pbwB+DaCq66tPquoOEdkDtAHy67jXnAZ7Dpbw5y+yeee7bYSGCJPO78o9F5xBfLStTzTGNC+iqvUnEHkTGA68D0xR1bU+ZSwyARijqnd5jm8Bhqrq/bWk7QQsAFJVtdLr2hDgNaC3qlZ5ulWHA6XAXOBRVS31yhIRmQRMAkhOTk6fOnWqL8WuV2FhITExMaecT1NSWFiIRLbk403lfL61nEqF81PDGHtGOAlRzXPmabB+zlbn4BCM9a6tzqNGjVqsqoPruue4LUdVvVlEYnEtu1dFRIFXgHdU9dAplrnaRGB6LYExBXgDuK1Gy/WXwC4gApgM/AJ4spZyT/ZcZ/DgwTpy5MhTLmRGRgYNkU9TUVxWwf+88QWf5rhnJI7t356HL+5O56SWgS6aXwXb5wxW52ASjPU+mTr7NEikqgdFZDrQAngIuAr4uYi8oKp/ruO27UBajeNUz7naTATuq3nCE5A/Bv5bVRfUKMtOz9tSEXkF+JkvdTC+Ka+sYv7GPD5esZNPVu+i4HA5F/Voy89+cBY9U2wTcGNMcPBlzHEscAdwJvA6MERV94hING78sK7gmAl0E5EuuKA4Ebixlvx7AAnA/BrnIoAPgde9J96ISIqq7hS359h4YNVxa2nqVVFZxYJN+/l45Q4+WbWLA8XlxESGMbpXMr0i8rj7qrMDXURjjDmtfGk5XgP8UVW/qnlSVYtF5M66blLVChG5H5iDW8oxRVVXi8iTwCJVnelJOhGYqscOfl4HnA8kisjtnnPVSzbeEpE2gADLgB/7UAfjpbJKWbjZ00JctYu8ojKiI0K5uGcyV/RL4fzubYgKDyUjIyPQRTXGmNPOl+D4OFDdlYmItACSVXWLqs6t70ZVnQXM8jr3mNfx47Xc9ybwZh15XuhDmU0tKquUzC37+XjFTmav2sW+wlJahIdyUc+2XNEvhZFntSUq3NYoGmOML8HxPeCcGseVnnPW19ZEqCozlm3nd7PXsetgCVHhIVzUI5nL+6Uw6qy2tIiwgGiMMTX5EhzDVLWs+kBVyzxjgqYJ2LyviF/NWMl/svPonxbPf1/ekwt7tLUF+8YYUw9ffkPuFZGx1WOEIjIO2OffYplTVVZRxd+/3Mif52UTGRrCU+P7cOOQjoSG2LMTjTHmeHwJjj/GTYL5C24STA5wq19LZU7Jd5v3818friR7TyGX90vhsSt62fMTjTHmBPiyCcBGYJiIxHiOC/1eKnNS8ovLeGb2WqZm5tAhvgWv3H42o3q0DXSxjDGmyfFp4ElELgd6A1FueSGo6vd2pTGBoap8tGwHT/07i/zD5fzo/K785OJuREfYuKIxxpwMXzYB+BvucVKjgJeBCcB3fi6X8dHWvCJ+NWMVX2/YR/+0eN64qi+92ttONsYYcyp8aVqco6r9RGSFqj4hIn8AZvu7YKZ+JeWV/PObzbwwdwPhoSE8Oa43Nw3tZBNujDGmAfgSHEs8X4s9z1bMA1L8VyRTn215xbz13VamZeZwoLicy/q249dX9rYJN8YY04B8CY7/EpF44P+AJYAC//BrqcwxKquUL9fv4Y35W8lYv5cQEUb3TObWczpxzhlJgS6eMcY0O/UGRxEJAeaqaj7wvoj8G4hS1YLTUrogl1dYyrRFuby1cCu5Bw7TplUkD1zYjRuGpJES1yLQxTPGmGar3uDoebjwi8BAz3Ep7iHDxk9UlSXb8nlzwVY+XrGTssoqhnVtzS8v7cklvZMJD22eDxg2xpjGxJdu1bkicg3wgdeTM0wDKiqtYObyHbwxfytZOw8SExnGDUPSuHlYJ7oltwp08YwxJqj4Ehx/BDwCVIhICW6XHFVVWy9wiqqqlAWb8pi+JJdPVu2iuKySHu1a8fRVfRg/oIPtf+1a9b4AACAASURBVGqMMQHiyw451mxpYNl7CvlgSS4zlm5nR0EJrSLDGNu/PRPSU0nvlED1RgvGGGMCw5dNAM6v7bz3w49N/Q4UlfGvFTt4f3Euy3MLCA0Rzu+WxC8v68noXsn2HEVjjGlEfOm3+3mN91HAEGAxYA8dPo6yiiq+WLuHD5bkMm/dHsorlZ4psfzq8p6MHdCetq1sbaIxxjRGvnSrXlnzWETSgOf9VqJmoKi0gj/N3cC0RTnkF5eTFBPJ7ed05qqBqba1mzHGNAEnM+MjF+jpS0IRGQP8CQgFXlbVZ7yu/xG3Zyu4/Vvbqmq859ptwK88136jqq95zqcDrwItgFnATxrTLNrvNu/nZ+8tJ+dAMZf1TWFCeirnnZlEmC3BMMaYJsOXMcc/43bFAQgBBuB2yjnefaHAi8BoXEDNFJGZqppVnUZVH66R/gE86ylFpDXwa2Cw53sv9tx7AHgJuBtYiAuOY2gEe72WlFfy7Jx1/PM/m0lLiObdScMZ0qV1oItljDHmJPjSclxU430F8I6q/seH+4YA2aq6CUBEpgLjgKw60t+AC4gAPwA+U9X9nns/A8aISAYQq6oLPOdfB8YT4OC4LCefn05bxsa9RdwyrBOPXtrDlmEYY0wT5stv8OlAiapWgmsRiki0qhYf574OQE6N41xgaG0JRaQT0AX4op57O3heubWcD4iyiipemLuBv2ZkkxwbxRt3DuG8bm0CVRxjjDENxKcdcoCLgULPcQvgU+CcBizHRGB6dQBuCCIyCZgEkJycTEZGxinnWVhYeCSfbQcr+cfKMnIOVXFehzBu6BFC5fbVZGw/5W/TqNSsc7CwOgeHYKwzBGe9T6bOvgTHKFWtDoyoaqGIRPtw33YgrcZxqudcbSYC93ndO9Lr3gzP+VRf8lTVycBkgMGDB+vIkSNrS3ZCMjIyOPe88/nblxv508INxEdH8M/b+nJRz+RTzruxysjIoCF+dk2J1Tk4BGOdITjrfTJ19mUKZZGIDKo+8MwWPezDfZlANxHpIiIRuAA40zuRiPQAEoD5NU7PAS4RkQQRSQAuAeao6k7goIgME7eNzK3ARz6UpUHsKKzimpe+5dlP1zOmTwqfPnR+sw6MxhgTrHxpOT4EvCciO3D7qrYDrj/eTapaISL34wJdKDBFVVeLyJPAIlWtDpQTgak1l2Oo6n4ReQoXYAGerJ6cA9zL0aUcszkNk3Eqq5Qp32zmd98eplVUBS/eOIjL+9nzno0xprnyZROATE/r7izPqXWqWu5L5qo6C7fcoua5x7yOH6/j3inAlFrOLwL6+PL9G8qynHyenrWGgW1DmXz3BbRpFXk6v70xxpjT7LjdqiJyH9BSVVep6iogRkTu9X/RGo/0Tgl8cO85PDgw0gKjMcYEAV/GHO9W1fzqA89C/Lv9V6TGaVBHe1qGMcYEC1+CY6jUiAqenW8i/FckY4wxJrB8mZDzCfCuiPzdc/wjGsF2bcYYY4y/+BIcf4FbTP9jz/EK3IxVY4wxplk6breqqlbhNvnegtsv9UJgjX+LZYwxxgROnS1HEemO2wz8BmAf8C6Aqo6q6x5jjDGmOaivW3Ut8DVwhapmA4jIw/WkN8YYY5qF+rpVrwZ2AvNE5B8ichFuhxxjjDGmWaszOKrqDFWdCPQA5uG2kWsrIi+JyCWnq4DGGGPM6ebLhJwiVX1bVa/EPQVjKW4GqzHGGNMs+bIJwBGqekBVJ6vqRf4qkDHGGBNoJxQcjTHGmGBgwdEYY4zxYsHRGGOM8WLB0RhjjPFiwdEYY4zxYsHRGGOM8WLB0RhjjPHi1+AoImNEZJ2IZIvIo3WkuU5EskRktYi87Tk3SkSW1XiViMh4z7VXRWRzjWsD/FkHY4wxwceX5zmeFBEJBV4ERgO5QKaIzFTVrBppugG/BEao6gERaQugqvOAAZ40rYFs4NMa2f9cVaf7q+zGGGOCmz9bjkOAbFXdpKplwFRgnFeau4EXVfUAgKruqSWfCcBsVS32Y1mNMcaYI0RV/ZOxyARgjKre5Tm+BRiqqvfXSDMDWA+MAEKBx1X1E698vgCeU9V/e45fBYYDpcBc4FFVLa3l+08CJgEkJyenT5069ZTrVFhYSExMzCnn05RYnYOD1Tl4BGO9a6vzqFGjFqvq4Lru8Vu3qo/CgG7ASNym5l+JSF9VzQcQkRSgLzCnxj2/BHYBEcBk3CboT3pnrKqTPdcZPHiwjhw58pQLm5GRQUPk05RYnYOD1Tl4BGO9T6bO/uxW3Q6k1ThO9ZyrKReYqarlqroZ14rsVuP6dcCHqlpefUJVd6pTCryC6741xhhjGow/g2Mm0E1EuohIBDARmOmVZgau1YiIJAHdgU01rt8AvFPzBk9rEhERYDywyh+FN8YYE7z81q2qqhUicj+uSzQUmKKqq0XkSWCRqs70XLtERLKAStws1DwAEemMa3l+6ZX1WyLSBhBgGfBjf9XBGGNMcPLrmKOqzgJmeZ17rMZ7BR7xvLzv3QJ0qOX8hQ1eUGOMMaYG2yHHGGOM8WLB0RhjjPFiwdEYY4zxYsHRGGOM8WLB0RhjjPFiwdEYY4zxYsHRGGOM8WLB0RhjjPFiwdEYY4zxYsHRGGOM8WLB0RhjjPFiwdEYY4zxYsHRGGOM8WLB0RhjjPFiwdEYY4zxYsHRGGOM8WLB0RhjjPFiwdEYY4zxYsHRGGOM8eLX4CgiY0RknYhki8ijdaS5TkSyRGS1iLxd43yliCzzvGbWON9FRBZ68nxXRCL8WQdjjDHBx2/BUURCgReBS4FewA0i0ssrTTfgl8AIVe0NPFTj8mFVHeB5ja1x/nfAH1X1TOAAcKe/6mCMMSY4+bPlOATIVtVNqloGTAXGeaW5G3hRVQ8AqOqe+jIUEQEuBKZ7Tr0GjG/QUhtjjAl6oqr+yVhkAjBGVe/yHN8CDFXV+2ukmQGsB0YAocDjqvqJ51oFsAyoAJ5R1RkikgQs8LQaEZE0YLaq9qnl+08CJgEkJyenT5069ZTrVFhYSExMzCnn05RYnYOD1Tl4BGO9a6vzqFGjFqvq4LruCfN7qeoXBnQDRgKpwFci0ldV84FOqrpdRLoCX4jISqDA14xVdTIwGWDw4ME6cuTIUy5sRkYGDZFPU2J1Dg5W5+ARjPU+mTr7s1t1O5BW4zjVc66mXGCmqpar6mZcK7IbgKpu93zdBGQAA4E8IF5EwurJ0xhjjDkl/gyOmUA3z+zSCGAiMNMrzQxcqxFPl2l3YJOIJIhIZI3zI4AsdX3A84AJnvtvAz7yYx2MMcYEIb8FR1WtAO4H5gBrgGmqulpEnhSR6tmnc4A8EcnCBb2fq2oe0BNYJCLLPeefUdUszz2/AB4RkWwgEfinv+pgjDEmOPl1zFFVZwGzvM49VuO9Ao94XjXTfAv0rSPPTbiZsMYYY4xf2A45xhhjjBcLjsYYY4wXC47GGGOMFwuOxhhjjJdAbwLQfFSWw771sGsV7FoBe9ZASn845wGIbh3o0gUvVRAJdCmMMU2MBceTcTgfdq+GXSvda/dKFwwry9z1sCho3RU2fgHf/QOG3wfD74WouIb5/jnfwfy/wI6l0ONKGHQLtO3ZMHk3F/uyYeFLsOwdSE2HcS9CfMdAl8oY00RYcPTFwZ2w+FV6r54Hyx6A/G1Hr7VsA+36wrB7ILmve594JoSGwe4syPgtfPkMLPyba0UO/TFEnsS+hpUVsPZfMP9FyM10gbbDYPhuMix4EVLPhkG3Qu+rILJVw9W9KVGFLd+4n9H6TyA0As66FLI/h7+eA5f+DgbcaC1JY8xxWXD0RXkxfPk7oqM7QNehkH4HtOvnAmGr5LrvS+4F178BO5fDvN/CF0/Bgr/CiIfg7LsgIvr437ukAJa8AQv/DgXbIKELXPYs9L/BBdmifbB8Kix5HWY+ALMfhT5XwaDbXMA80UCg6oL/rhWwaxVdNmdD6GKIiIGIlp5XHe/DoyEk9MS+X0OoKIPVH7rW9K4VEJ0EF/wCzr4TYtrCgS3w4T3w0b2wbhZc8TzEtDn95TTGNBkWHH2R0AX+azuZ32ae3Ia9Kf3hxqmQuxjm/QY++x/3i/zcRyD9dgiP+v49B7a6gLjkdSg7BJ1GwKXPQPcxxwaglklwzv2u6zY3E5a8Bqs+hKVvQtJZrsu1/w0unbfKCsjbADtXuKCyc7nrJi7J9yQQOiKwbfr3761L667QZwL0uw6Sup3IT+nEFe+Hxa+4rutDO119r3zBfe/wFkfTJXSG2//t/jCZ+yT8dRiMfQF6XO7f8hljmiwLjr4ICXEto1OVmg63fAhb58O8p+GTX8C3L8B5P4WBt0BYBORkusC5ZiYg0OdqGHYvdBhUf94ikDbEvcY8A6s+gKVvwKe/gs+fcN2LfSdAcd7RYLh7NVSUuPvDoqBtL+g93rWKU/pD2158+Z+FjDx3OJQVQVmh52sRlBcdfV99vrQQchbA18/CV7+H9gOh73XQ55r6W9gn6sh44tuuVX/GhTD2L3DmRXW3lENCXbf2GRfBh5Ng6o0w4CYY89uGGwtuqsqKaXVwPZQPPfaPCmOCmAXHQOg03LVkNn3pguTHj8B/noeYZNf6i4xzv8iHTIK41BPPP7IVpN/mXnvWuG7ZFVM9ARcXDNr1g8F3Qko/9z6puxsn9SbiWrbhUdAy0bfvf3AnrHofVk6DOb+ET/8buo50gbLnFSc2JlpV6bpF96yBvWshZyFs+AxCw10Lcdi9kNzb9/ySe8FdX8CXv4NvnoPNX8H4v0KX833PozmpqoL3bid9wxxY9l9uqCBtiOuSTxsCcWk2RmuCkgXHQOp6gfulnD3XTdopKYBLf+9aNCczaac2bXvCmP+Fix93gTeuA8R38u8vvNgU19V7zv2wdx2smOYC5Ywfw79bQI/LoN/1rsUXGu7uqayAA5tdANyz1n3duxb2bYDK0qN5x3eEC/6fG7ONaXty5QuLgIv+x3VRf/gjeO1KGHafO+dry6msCPI2wv6N7nNL6Aytz4DYDq6noan49k+wYQ45qeNJ69TZ/RtZ/JqbQAYQ0w7SzoZUT69ESn9rXTYWFaVuRnzH4dAiPtClaXYsOAaaCHS72L38KSwCOo/w7/eoTZuzXNC58FduCcqKd93kmVXvQ3QipA1zLcO8DUeXwgDEdYS2PeCMUdCmJ7TpAW26N+xM3LSz4cdfw2e/djN+sz+Hq/9+9Hr5Ydi/2QXA6kCYt8l9PbSz9jzDotwYdeIZbvw18QwXNBPPgFYpjasVtuU/MPcp6H0VG5NuI23UKHe+shx2r3Jd/LmZkPsdrPmXuxYS7lqXHYe5bvr2gxpXnfylqtINgZx5sat/oJUVu6GBTfMgNNKNnw+4yf1/CcSkuGbIgqM5PUSg41D3GvMMbJzrWpS7Vrjg0e1iTwDs4bp4G6rlfDwRLeHyZ92Y7Ef3w8sXM6DVWbCkAA5uB/Ro2ugkF+S6joLErp6gd6brpj6wpUYQ3eRavBs+PTbgh0fXCJhd3Suhi/vaKuX0tjgL98D0H7oW75UvwIIlR6+Fhrvx4vYDYeiko+lzM90fOLmZsGiKm+CU3Nd13/e9tnm3Xub9rxtL//o5uPl914oOlJKD8Pb1bnz/4sfh4A5Y+R6s/sC19Ptd55Ys2drnU2LB0Zx+YZ71h2ddGuiSHHXmRXDvt/Dp/xCSvRC6jDja4qsOaPVN3Eno5LrJa6qqhILcY4Nm3kY3EWrtLKgqP5q2usXZuiu07uJ5eQJobGrt48Enq6oS3r/LzUq++X2Iij3+PTFtXeukeoZvSQGsnO5mR8/6mZv41Wu8C5Qdh598a7JmqzW6NfQc6/69BNK62S4w9r7azeh+fTzcNA06n3v6y1K8H96a4MpxzctushvAJb+B9XPcJLX5L7pWbvuBrjXZ5xr/79JVVeVasYumuJ3Ckrq7uQBte7mvrbs2uRatBUdjqrVIgHF/YUlGxskt2fEWEuqCZkInN75aU2UFHMz1dNtu8rw2u3HXjXOPziIG15V5zv1w4WMN07r88vew+Us3w7ddn5PLIyrOrSM9+07YscwtOVr5npv4ldjNbUgx4MbalxDVVLwfche5VlDOd7B9sZuBXK1VipuYln57YLZh3L8ZPviRG2sd/5L7g+K1sfDmBLjh7e9/rv5UuBfeGO+Cz3VvuLH7amGR0GusexXudZ/FsrfdHy6f/BLOGuMC5ZkNPHxTlAfL3oRFr7h/u9GJkDbUzRdYNwu0ylO+KDfE0ra3mxRXHTRjkhttt7wFR2MCITTMdWkmdHbjRDVVVUHhrqMBc1MGfPNHtznD+JfcL8KTtdEzU7f/jTDw5lOoQA3tB7jXJU/B6hkuUH72P25NaY/L3IYUXUe5X4J52W7G8TZPMNy3zuUhoW7m9KBb3S/XtCFuhvL8v8DcJ+Cr/3O/3Ifd41rxp0P5YZh2iyv3da97Zm23g9s/dkHq7Ynu/Flj/F+Wgzvg9XGQnwM3vlt/UI5p47arHH6vW7a1/B03hLHmX9CyDT1iekPMZuh0jmvhncxGITkLXStx9Qw3Ya7jOW5eQc8rj/77LD/sguTuLNiT5XpMNs6F5W8fzSs60Y3h9rgCeo07+Ul2fmDB0ZjGJiQEYtu7V+dzXRBr1wc+f9yN/V3/5smN7x3cAe/f7cZ1L3+24f9ij2gJA29yrz1rXZBc/g5kfeRm8ZYfhsP7XdqoeBcE+13nvnYY9P21xHGp0G2028x/wUuuCzfzZTjrMrfpRadz/NfqUIWPf+q+903vuT9iqsW0gdv+BW9eDe/eDBOmuBabvxzYCq+Pda20Wz5w9fZVSj/3Gv2km3C2Yhqt138B/85w16MTXTd4x+FuiVm7/nV34ZccdLPOM6fAntUQGeu60Qf/sPbxzfAWR8euayrKc/fvznJfc75zLdzZ/w+6XOAmevW4IuBj2H4NjiIyBvgTEAq8rKrP1JLmOuBx3MyH5ap6o4gMAF4CYoFK4GlVfdeT/lXgAqDAk8XtqrrMn/UwJqBE4NyHXYCZcS9MGQM3Tz+xNbCVFW4CTvlhuO61htnUoj5te3iWEP0a1v4bVr7vuq07DnXBMLGb713E7frA+BfhosdccMx8GdZ9DCkDYPj9buOK6iVBDWXxq7DsLbcNYbfR378e3Rpu/ch1r753O1w92f1Sb2j7sl1gLCt03y81/eTyCQ0/Ms7/7bx5jOzXEbZ+C9vmu69r/+3Shbd0s7irA2bq2W7MPPOfrqu2rNB1MV/5ghvLPJmJcy0T3RK2mmuLd2fBquluFvtH98G/H4Zul7hNULpf6ttWmw3Mb8FRREKBF4HRQC6QKSIzVTWrRppuwC+BEap6QESq29TFwK2qukFE2gOLRWSOqlbva/ZzVT2BPc2MaQb6Xee6nd69BV4e7QKkrxsgfPGU+0V49ctu7Od0CYt0v0SrJ46cilbJcOF/uz8UVrzrZst+cBd89pibVZt+uwvAp2r7EteKOeMiFxzrEhXnWnJvT3QTnCpKXau5oezOcl2pWuW6chtqCYmI65pOPMNtLwlwaJcnUM6Hbd9CxjOAuu5urXRjhn0mwNk/9M/yneRekPwYXPg/7ue/arrb5Wvtv13A7nGZ+/5nXHjaJmj5s+U4BMhW1U0AIjIVGAdk1UhzN/Ciqh4AUNU9nq/rqxOo6g4R2QO0AfIxJph1HQl3zIa3rnUtyOvf/P4sWW/rPnE7MKXfAf2uPR2l9K+IaBh8hxvLzP7cjUt+/jh8/Uf35JX+E0/+l3fxfph2m5socs3Lx59hGdnKdbu+e5Pb2L6ixE1SOlU7lsIbV7mgdOvHbo2vP7Vq557o0/sqd1xS4Lo7ty1wTx7qf33D/OFxPCKudZya7mbgbv2PmxWd9ZFruUbFuy7swXe6cW5/FkVVj5/qZDIWmQCMUdW7PMe3AENV9f4aaWYA64ERuK7Xx1X1E698hgCvAb1VtcrTrTocKAXmAo+qaileRGQSMAkgOTk5ferUqadcp8LCQmJiTtP6u0bC6tw4RZbspd+KJ2lxeAdrezzInuTaA2RkyR4GL3qYkqg2LB34e6pCa/+ruynUuT4xhzbRbcNk4g6uYV/i2azvfi9lkfXPbv1enbWSfiueIj5/JUsHPsOhWN83zg+pLKNX1u9Jyssk+4w7yU07+THI2II19FvxJBVhMSwb8CQlLVJOOq/aNMXPWqrKSTiwnOTdX5G0byEbut3NrhTfZ97WVudRo0YtVtXBdd6kqn55ARNw44zVx7cAf/FK82/gQyAc6ALkAPE1rqcA64BhXucEiMQFzceOV5b09HRtCPPmzWuQfJoSq3MjVnxA9ZXLVX8dq/r1c6pVVcdeLy9VnTxK9X9TVfdl15tVk6lzfSorVP/zZ9Wn2qr+tqPq8mnf/5nU8L06f/G/7meZOeXkvn95qerUm10eX/3h5PLYmKH6m3aqfxqomp9zcnkcR5P/rEuLVMuKT+iW2uoMLNJ64oY/u1W3A2k1jlM952rKBRaqajmwWUTWA91w45OxwMfAf6vqguobVLV6365SEXkF+Jm/KmBMo9Yi3i3in3GP61YsyHV781Z3BX72mFs3eN3rp2/5QyCFhLr1oN0ucT+TD+6CNR/B5X88/vM7N3zmlrgMuMmNXZ6MsAiY8IrbQ3juE24McuSjR7t4K8rg8AE3Y/fwAdeFe8xxHix/131Wt8xo2CfZNCenaXKOP4NjJtBNRLrgguJE4EavNDOAG4BXRCQJ6A5sEpEIXIvydfWaeCMiKaq6U0QEGA+s8mMdjGncwiLdJJvY9vDtn93EimtedlvXLXwJht7j1o8Fkzbd4c5P3c9j3tOwdShc/oej42neDmxxE2qS+7gHiZ/KZJPQMLjq726/0y+fcfsIlxe7QFheVPd9IWHQorWbwXn15MBseGCO4bfgqKoVInI/MAc3njhFVVeLyJO45uxMz7VLRCQLt2Tj56qaJyI3A+cDiSJyuyfL6iUbb4lIG1zX6jLgx/6qgzFNQkiIm7wQmwqfPAqvXOYW23dId+vbglFIKJz7kHvyyowfu+UWWR/BZX849tFr5SUw7Va3rvH61xumVRISCmP/7J4gs32xC3QtElzwaxHvOfacq74WEdNod4oJVn5d56iqs4BZXuceq/FegUc8r5pp3gTerCPP07hfkzFNyLAfu8eFvX+3W4B97auB35c00Nr2gDs/d7N1M56BLd/AFX90O7kAzP6526f0hnfd/p8NJSQERtazDMQ0erZDjjHNSa9xbgccxLVcjOvqPP9nnlbkPW5Xm77XklrcCja+Duf97PRsAWeaFAuOxjQ3p3ORf1PSrg/c/QV8/Qf46v84s6rCrRsd9V+BLplphJrQI8uNMeYUhYa7GaR3f0Fuh8vhmn82uUcpmdPDgqMxJvik9Ce726TjP1LLBC0LjsYYY4wXC47GGGOMFwuOxhhjjBcLjsYYY4wXC47GGGOMFwuOxhhjjBcLjsYYY4wXC47GGGOMF3F7fzdvIrIX2NoAWSUB+xogn6bE6hwcrM7BIxjrXVudO6lqnQ/6DIrg2FBEZJGqDg50OU4nq3NwsDoHj2Cs98nU2bpVjTHGGC8WHI0xxhgvFhxPzORAFyAArM7BweocPIKx3idcZxtzNMYYY7xYy9EYY4zxYsHRGGOM8WLB0QciMkZE1olItog8GujynA4iskVEVorIMhFZFOjy+IuITBGRPSKyqsa51iLymYhs8HxNCGQZG1oddX5cRLZ7Pu9lInJZIMvY0EQkTUTmiUiWiKwWkZ94zjfbz7qeOjfbz1pEokTkOxFZ7qnzE57zXURkoed3+LsiEnHcvGzMsX4iEgqsB0YDuUAmcIOqZgW0YH4mIluAwararBcLi8j5QCHwuqr28Zz7PbBfVZ/x/DGUoKq/CGQ5G1IddX4cKFTVZwNZNn8RkRQgRVWXiEgrYDEwHridZvpZ11Pn62imn7WICNBSVQtFJBz4BvgJ8AjwgapOFZG/ActV9aX68rKW4/ENAbJVdZOqlgFTgXEBLpNpIKr6FbDf6/Q44DXP+9dwv1CajTrq3Kyp6k5VXeJ5fwhYA3SgGX/W9dS52VKn0HMY7nkpcCEw3XPep8/ZguPxdQByahzn0sz/gXko8KmILBaRSYEuzGmWrKo7Pe93AcmBLMxpdL+IrPB0uzab7kVvItIZGAgsJEg+a686QzP+rEUkVESWAXuAz4CNQL6qVniS+PQ73IKjqcu5qjoIuBS4z9MVF3TUjTsEw9jDS8AZwABgJ/CHwBbHP0QkBngfeEhVD9a81lw/61rq3Kw/a1WtVNUBQCqu56/HyeRjwfH4tgNpNY5TPeeaNVXd7vm6B/gQ948sWOz2jNdUj9vsCXB5/E5Vd3t+qVQB/6AZft6eMaj3gbdU9QPP6Wb9WddW52D4rAFUNR+YBwwH4kUkzHPJp9/hFhyPLxPo5pntFAFMBGYGuEx+JSItPQP4iEhL4BJgVf13NSszgds8728DPgpgWU6L6gDhcRXN7PP2TNT4J7BGVZ+rcanZftZ11bk5f9Yi0kZE4j3vW+AmUq7BBckJnmQ+fc42W9UHnqnOzwOhwBRVfTrARfIrEemKay0ChAFvN9c6i8g7wEjcI212A78GZgDTgI64R51dp6rNZgJLHXUeietmU2AL8KMaY3FNnoicC3wNrASqPKf/CzcG1yw/63rqfAPN9LMWkX64CTehuMbfNFV90vM7bSrQGlgK3KyqpfXmZcHx/7d3By82R2EYx7+PlDBFio0FYYNCKQuTUv4BC1KYhbWNnRQb/4CVMsuRWYjMxkpmMWUhpFnJympWNlKjlMZr8TtT5myUMjPXfD+7e+7p9DuLe597zq33lSRpJa9VJUnqGI6SJHUMR0mSOoajJEkdw1GSpI7hKGmFJGeTPF/r55DWkuEoSVLHcJRGVJKrrXfdfJLJVnB5Mcm91stuNsnuNvdEktet2PTMcrHpd3VKWgAAAVVJREFUJIeSvGz9794nOdiWH0vyNMnHJNOt2oq0YRiO0ghKchi4BIy3IstLwBVgO/Cuqo4CcwzVbwAeAjer6hhDxZTl8WngflUdB04zFKKGoYPDDeAIcAAY/+ebktaRzX+eImkdOgecBN62Q91WhqLZP4HHbc4j4FmSHcDOqppr41PAk1Y/d29VzQBU1XeAtt6bqlpor+eB/QyNY6UNwXCURlOAqaq6tWIwudPN+9v6kL/XnVzC7wptMF6rSqNpFriQZA9Akl1J9jF8ppe7D1wGXlXVV+BLkjNtfAKYa93hF5Kcb2tsSbJtVXchrVP+GpRGUFV9SHIbeJFkE/ADuA58A0619z4z/C8JQ5ueBy38PgHX2vgEMJnkblvj4ipuQ1q37Moh/UeSLFbV2Fo/hzTqvFaVJKnjyVGSpI4nR0mSOoajJEkdw1GSpI7hKElSx3CUJKnzCzpmgFIrFRwRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','validation'])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','validation'])\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZODANwSBV8F"
      },
      "source": [
        "## **3.2 Bi-LSTM architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efDiYbJBbErA"
      },
      "outputs": [],
      "source": [
        "text_input=layers.Input(shape=(max_len_text,))\n",
        "text_embedding = layers.Embedding(\n",
        "    len(word_index_text)+1,\n",
        "    300,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix_text),\n",
        "    mask_zero=True,trainable=False,\n",
        "    input_length=max_len_text)(text_input)\n",
        "sentiment_input=layers.Input(shape=(max_len_sentiment,))\n",
        "sentiment_embedding = layers.Embedding(\n",
        "    len(word_index_sentiment)+1,\n",
        "    300,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix_sentiment),\n",
        "    mask_zero=True,trainable=False,\n",
        "    input_length=max_len_sentiment)(sentiment_input)\n",
        "con=layers.Concatenate(axis=1)([text_embedding,sentiment_embedding])\n",
        "bi_lstm=layers.Bidirectional(LSTM(16,return_sequences=True))(con) #bi-lstm\n",
        "\n",
        "d = layers.Dense(8,activation=\"relu\")(bi_lstm)\n",
        "d = layers.Dropout(0.3)(d)\n",
        "d = layers.Dense(4,activation=\"relu\")(d)\n",
        "output=layers.Dense(1,activation='sigmoid')(d)\n",
        "\n",
        "model2=keras.Model(inputs=[text_input,sentiment_input],outputs=[output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "yGWaaIKebVkw",
        "outputId": "b3d3a6c5-483e-4d27-e544-41ad155f40a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-10371b35f581>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_sentiment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_sentiment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m-> 2955\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m                 ))\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[1;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[0;31m# Run forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \"\"\"\n\u001b[1;32m    451\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 452\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask, initial_state, constants)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       y = self.forward_layer(forward_inputs,\n\u001b[0;32m--> 706\u001b[0;31m                              initial_state=forward_state, **kwargs)\n\u001b[0m\u001b[1;32m    707\u001b[0m       y_rev = self.backward_layer(backward_inputs,\n\u001b[1;32m    708\u001b[0m                                   initial_state=backward_state, **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m           (last_output, outputs, new_h, new_c,\n\u001b[0;32m-> 1255\u001b[0;31m            runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mlstm_with_backend_selection\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   1649\u001b[0m     \u001b[0;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m     \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefun_standard_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1651\u001b[0;31m     \u001b[0m_function_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_gpu_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_function_register\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1783\u001b[0m   \u001b[0mconcrete_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1785\u001b[0;31m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_gradient_functions_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1786\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36madd_gradient_functions_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m   2104\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m     forward_function, backward_function = (\n\u001b[0;32m-> 2106\u001b[0;31m         self._delayed_rewrite_functions.forward_backward())\n\u001b[0m\u001b[1;32m   2107\u001b[0m     \u001b[0mforward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \u001b[0mbackward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m     \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    647\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m           \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m           func_graph=backwards_graph)\n\u001b[0m\u001b[1;32m    650\u001b[0m       \u001b[0mbackwards_graph_captures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackwards_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_captures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m       captures_from_forward = [\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             src_graph=self._func_graph)\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 680\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    681\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 680\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    681\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_IfGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   true_grad_graph = _create_grad_func(\n\u001b[0;32m--> 121\u001b[0;31m       true_graph, grads, util.unique_grad_fn_name(true_graph.name))\n\u001b[0m\u001b[1;32m    122\u001b[0m   false_grad_graph = _create_grad_func(\n\u001b[1;32m    123\u001b[0m       false_graph, grads, util.unique_grad_fn_name(false_graph.name))\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_create_grad_func\u001b[0;34m(func_graph, grads, name)\u001b[0m\n\u001b[1;32m    390\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m       \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m       func_graph=_CondGradFuncGraph(name, func_graph))\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    389\u001b[0m   return func_graph_module.func_graph_from_py_func(\n\u001b[1;32m    390\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m       \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m       func_graph=_CondGradFuncGraph(name, func_graph))\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_grad_fn\u001b[0;34m(func_graph, grads)\u001b[0m\n\u001b[1;32m    380\u001b[0m   result = gradients_util._GradientsHelper(\n\u001b[1;32m    381\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m       src_graph=func_graph)\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 680\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    681\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 680\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    681\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ReshapeGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    790\u001b[0m   return [\n\u001b[1;32m    791\u001b[0m       array_ops.reshape(\n\u001b[0;32m--> 792\u001b[0;31m           _IndexedSlicesToTensorNoWarning(grad), array_ops.shape(op.inputs[0])),\n\u001b[0m\u001b[1;32m    793\u001b[0m       \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m   ]\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m   \"\"\"\n\u001b[0;32m--> 649\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    685\u001b[0m             return constant_op._tensor_shape_tensor_conversion_function(  # pylint: disable=protected-access\n\u001b[1;32m    686\u001b[0m                 input_shape)\n\u001b[0;32m--> 687\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m    267\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 268\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m--> 290\u001b[0;31m       \"Const\", [], [dtype_value.type], attrs=attrs, name=name).outputs[0]\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    693\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    694\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "optim = keras.optimizers.Adam(lr=0.001)\n",
        "metrics = [\"accuracy\"]\n",
        "\n",
        "model2.compile(loss=loss, optimizer=optim, metrics=metrics)\n",
        "\n",
        "history=model2.fit([train_text,train_sentiment],y_train,epochs=15,batch_size=128,\\\n",
        "                  validation_data=([valid_text,valid_sentiment],y_valid),verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4zxNNvPyZsb"
      },
      "source": [
        "Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "E4AZJLkSyXzj",
        "outputId": "99476f03-47a0-4c6c-a294-b5c712cccead"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','validation'])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','validation'])\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgZY_rqsauJn"
      },
      "source": [
        "## **3.3 Models Comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGjuNJm-lCKl"
      },
      "outputs": [],
      "source": [
        "#@title Helper function\n",
        "def jaccard(str1,str2): \n",
        "    a=set(str1.lower().split()) \n",
        "    b=set(str2.lower().split())\n",
        "    c=a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "\n",
        "def get_index(pred):\n",
        "    pred_index=[]\n",
        "    for vector in pred:\n",
        "      index=[]\n",
        "      for i,value in enumerate(vector):\n",
        "        if value == 1:\n",
        "          index.append(i)\n",
        "      pred_index.append(np.array(index))\n",
        "    return pred_index\n",
        "    \n",
        "def get_text(x):\n",
        "  selected_text=[]\n",
        "  text=x[0]\n",
        "  index=x[1]\n",
        "  text=text.split()\n",
        "  l=len(text)\n",
        "  for i in index:\n",
        "    if i < l:\n",
        "      selected_text.append(text[i])\n",
        "  return selected_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcSjH4NwkHT1"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-iyv84BkB1A",
        "outputId": "13036bdb-7e19-472e-a249-816b2ac18250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean training Jaccard score: 0.553316060610876\n"
          ]
        }
      ],
      "source": [
        "pred_lstm = model1.predict([test_text,test_sentiment])\n",
        "pred_lstm=np.round(np.squeeze(pred_lstm))\n",
        "\n",
        "test_lstm = test.copy()[['textID','text','selected_text','sentiment']]\n",
        "test_lstm['prediction']=get_index(pred_lstm)\n",
        "test_lstm['pred_text']=test_lstm[['text','prediction']].apply(lambda x: get_text(x),axis=1)\n",
        "test_lstm['pred_text']=test_lstm['pred_text'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "test_lstm['jaccard']=test_lstm.apply(lambda x: jaccard(x.selected_text,x.pred_text),axis=1)\n",
        "\n",
        "print('Mean training Jaccard score:',np.mean(test_lstm['jaccard']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgmzjoXSp7bY"
      },
      "source": [
        "Bi-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dil6iD8rp-mh",
        "outputId": "f6d59c3a-e12a-46f0-9c6c-eacabe718add"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean training Jaccard score: 0.5955218163330321\n"
          ]
        }
      ],
      "source": [
        "pred_bi_lstm = model2.predict([test_text,test_sentiment])\n",
        "pred_bi_lstm=np.round(np.squeeze(pred_bi_lstm))\n",
        "\n",
        "test_bi_lstm = test.copy()[['textID','text','selected_text','sentiment']]\n",
        "test_bi_lstm['prediction']=get_index(pred_bi_lstm)\n",
        "test_bi_lstm['pred_text']=test_bi_lstm[['text','prediction']].apply(lambda x: get_text(x),axis=1)\n",
        "test_bi_lstm['pred_text']=test_bi_lstm['pred_text'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "test_bi_lstm['jaccard']=test_bi_lstm.apply(lambda x: jaccard(x.selected_text,x.pred_text),axis=1)\n",
        "\n",
        "print('Mean training Jaccard score:',np.mean(test_bi_lstm['jaccard']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCz67WMBDF6v"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmKpKPzxAtlp"
      },
      "source": [
        "# 4.Sentiment Extraction using BERT and RoBERTa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WRC_by5ECzD"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQRY4yT7P8Xj"
      },
      "outputs": [],
      "source": [
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w4oGK5aEMhR",
        "outputId": "722cbdcb-3f3e-45c2-c069-16f5c1e26bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 36.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 49.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 30.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ],
      "source": [
        "# install transformers\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_arY0uBDB1-"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KcTOWPtDG5b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForTokenClassification\n",
        "from sklearn.metrics import jaccard_score\n",
        "from tqdm import tqdm\n",
        "from transformers import RobertaForTokenClassification, RobertaTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNuDauoPFaiO"
      },
      "source": [
        "## pre-trained BERT model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-9mVgINSLc9"
      },
      "outputs": [],
      "source": [
        "# drop start index and end index column from dataset\n",
        "data = data.drop(columns=['start_index', 'end_index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwQfu-iUTqwU",
        "outputId": "ee7c32d0-a14c-4f8a-c380-0b1c73ec5477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6846, 5)\n"
          ]
        }
      ],
      "source": [
        "data_split = np.array_split(data, 4)\n",
        "print(data_split[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFL0cNi6UC7W",
        "outputId": "c7225a9d-23be-4fee-9e1c-d9e881842135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6846, 5)\n"
          ]
        }
      ],
      "source": [
        "data = data_split[0]\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98lIf363Sram"
      },
      "outputs": [],
      "source": [
        "X = data[['text','sentiment']]\n",
        "y = data['selected_text']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "e4ca8f36b2404f5180f3a40d9d717ff3",
            "694eb34475b546eba7a3823cdd8b438d",
            "017d33c4d33c46868e5cc1bd48302356",
            "910de5f313ab4502aa2e8eb2961a2ccc",
            "6df015ed8c5d47e981e4b992f7a53e94",
            "fd29cc33f3cb4e5195263e0a0b82af67",
            "38de644afe5d42e0ae3e98c74e816c74",
            "eae671af63674b4eb483cf7f8ff803b2",
            "cde0e0432e5e48c29f9017693f0b3de0",
            "3c96e91e9a4d4baca1e0c968826e87e5",
            "2ae7d96cf8a24cbd9f1ddae5e380f29e",
            "29369daf87134f29a1aa7227b420d33f",
            "f0edf25d82194d95b66d2e3a0a68d31e",
            "d3e75ffce65a4defbcbec0c5fbeb68ac",
            "bd9c6297bf07477d95fc7947c4d1d61f",
            "fa1e04ed28304200b628d77f47b7b69c",
            "4b4e0a4860c145e3b64acc3f6bf5e186",
            "90986fb49951441582e8cf8c3c1e085d",
            "a7a44bcab41e4954a655b4787655bed4",
            "9560c45379ab4c8ea59aed294bd8a326",
            "55ee5bfaea0e477f9f046f91b977e23f",
            "4aa634def35b4d4cb0f666cc919336d6",
            "56eb19a571a04d3c9a8de8167a9b31d8",
            "5d27ae94556c4ace83b234a0866a9967",
            "306f8e838a014233938142fd35bda880",
            "48efa3450cce4769a2ee4bdc5029f57d",
            "64f6cc4747544b6ea9aeeb006a461806",
            "f5985cc269824b1d9b1da22ec14dabe9",
            "4f0bfb58fb194edb8406583a8f1a5140",
            "5b45bddf9a584feea35e2fe74f6f8bc1",
            "5a40265798fc4316ad80fd205eeeaf66",
            "bb09cc12a4874e6381ed0febf28cb216",
            "90401b4c62e6439f8e78e184c06b1fbb",
            "b7d433c587944ebfacec26e74c974757",
            "ec880502c76f45fe930afedd067a5d5a",
            "6156cc960aa24aaba6ec1691672d9f54",
            "773d45ac413040c0a662257990601b39",
            "84abb2c467414a8191bcb1e8e1c4dc08",
            "46763a55a76d40bfb23a411b03871fce",
            "37245d607fa045c583e7bd1c3eecf4d7",
            "3fa659a3560b4f65b41560ba6e626bcf",
            "2ce364cebe2b414185514128bbd90ccd",
            "0f9cacde8d4b45749cd223ff5214b270",
            "91b784d8a9604ee2b962f81cd08d54c0"
          ]
        },
        "id": "7X66xIUbFfyC",
        "outputId": "cd7240cb-ecea-4dba-da81-f0699a58a777"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4ca8f36b2404f5180f3a40d9d717ff3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29369daf87134f29a1aa7227b420d33f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56eb19a571a04d3c9a8de8167a9b31d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7d433c587944ebfacec26e74c974757",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQp_A_6iGEM4"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6KgYumMHXBz"
      },
      "outputs": [],
      "source": [
        "class OurDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "    self.encodings = encodings\n",
        "    self.labels = labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    input_ids = self.encodings[\"input_ids\"][idx]\n",
        "    attention = self.encodings[\"attention_mask\"][idx]\n",
        "    labels = self.labels[idx]\n",
        "    return input_ids.long(), attention.long(), labels\n",
        "  def __len__(self):\n",
        "    return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJGFWz_wHYf7",
        "outputId": "b4c3452a-d2a8-49d5-ea46-6276fa9572a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ],
      "source": [
        "encodings = tokenizer(list(X_train['text']), text_pair=list(X_train['sentiment']), max_length=32, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "test_encodings= tokenizer(list(X_test['text']), text_pair=list(X_test['sentiment']), max_length=32, padding=True, truncation=True,  return_tensors=\"pt\")\n",
        "y_encodings = tokenizer(list(y_train), max_length=32, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "y_test_encodings = tokenizer(list(y_test), max_length=32, padding=True, truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoNMwPe1H_uO"
      },
      "source": [
        "## Selected text extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79g5dOyvIKNm"
      },
      "outputs": [],
      "source": [
        "def map_selected_text(text_tensor, selected_text_tensor):\n",
        "  selected = []\n",
        "  \n",
        "  for each in selected_text_tensor:\n",
        "    if each ==101:\n",
        "      continue\n",
        "    if each ==102:\n",
        "      break\n",
        "    selected.append(each)\n",
        "  pos = []\n",
        "  # print(selected)\n",
        "  for each in selected:\n",
        "    pos.append((text_tensor == each).nonzero().flatten())\n",
        "  ret = torch.zeros(text_tensor.shape[0])\n",
        "  for each in pos:\n",
        "    ret[each] = 1\n",
        "\n",
        "  return ret\n",
        "\n",
        "\n",
        "map_selected_text(encodings[\"input_ids\"][1], y_encodings[\"input_ids\"][1])\n",
        "train_labels= []\n",
        "test_labels = []\n",
        "\n",
        "for i in range(len(encodings[\"input_ids\"])):\n",
        "  train_labels.append(map_selected_text(encodings[\"input_ids\"][i], y_encodings[\"input_ids\"][i]))\n",
        "\n",
        "for i in range(len(test_encodings[\"input_ids\"])):\n",
        "  test_labels.append(map_selected_text(test_encodings[\"input_ids\"][i], y_test_encodings[\"input_ids\"][i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK7_d5HRIOHx"
      },
      "source": [
        "## 4.1 BERT Architecture and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj4whQKQIUmu"
      },
      "outputs": [],
      "source": [
        "train_labels = torch.stack(train_labels).long()\n",
        "test_labels = torch.stack(test_labels).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXsCvfEQIXpm"
      },
      "outputs": [],
      "source": [
        "train_dataset = OurDataset(encodings, train_labels)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=64, shuffle=True)\n",
        "test_dataset = OurDataset(test_encodings, test_labels)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size=64, shuffle=False)\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z8_Ekz7IobN"
      },
      "outputs": [],
      "source": [
        "def evaluate(model,val_dataloader):\n",
        "  batch_score = []\n",
        "  batch_loss = []\n",
        "  with torch.no_grad():\n",
        "    for batch in val_dataloader:\n",
        "      inputs = batch[0]\n",
        "      attention = batch[1]\n",
        "      labels = batch[2]\n",
        "      outputs = model(inputs, attention_mask = attention, labels=labels)\n",
        "      logits = outputs.logits\n",
        "      loss = outputs.loss\n",
        "      preds = torch.argmax(logits, dim=2)\n",
        "      score = []\n",
        "      \n",
        "      for i in range(len(labels)):\n",
        "        score.append(jaccard_score(labels[i],preds[i]))\n",
        "      batch_score.append(np.sum(score)/len(score))\n",
        "      batch_loss.append(loss)\n",
        "\n",
        "\n",
        "  return np.sum(batch_score)/len(batch_score), np.sum(batch_loss)/len(batch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "perS4KUCI0K5",
        "outputId": "366830fa-c7a3-4350-ec26-3f3dc86c61c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "  0%|          | 0/75 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1/75 [00:18<23:07, 18.74s/it]\u001b[A\n",
            "  3%|▎         | 2/75 [00:37<22:42, 18.67s/it]\u001b[A\n",
            "  4%|▍         | 3/75 [00:55<22:07, 18.43s/it]\u001b[A\n",
            "  5%|▌         | 4/75 [01:13<21:39, 18.30s/it]\u001b[A\n",
            "  7%|▋         | 5/75 [01:31<21:22, 18.32s/it]\u001b[A\n",
            "  8%|▊         | 6/75 [01:49<20:53, 18.17s/it]\u001b[A\n",
            "  9%|▉         | 7/75 [02:07<20:29, 18.08s/it]\u001b[A\n",
            " 11%|█         | 8/75 [02:25<20:14, 18.13s/it]\u001b[A\n",
            " 12%|█▏        | 9/75 [02:44<19:56, 18.12s/it]\u001b[A\n",
            " 13%|█▎        | 10/75 [03:02<19:37, 18.12s/it]\u001b[A\n",
            " 15%|█▍        | 11/75 [03:21<19:46, 18.54s/it]\u001b[A\n",
            " 16%|█▌        | 12/75 [03:39<19:20, 18.41s/it]\u001b[A\n",
            " 17%|█▋        | 13/75 [04:05<21:15, 20.57s/it]\u001b[A\n",
            " 19%|█▊        | 14/75 [04:33<23:08, 22.77s/it]\u001b[A\n",
            " 20%|██        | 15/75 [04:51<21:21, 21.36s/it]\u001b[A\n",
            " 21%|██▏       | 16/75 [05:08<19:54, 20.25s/it]\u001b[A\n",
            " 23%|██▎       | 17/75 [05:26<18:47, 19.44s/it]\u001b[A\n",
            " 24%|██▍       | 18/75 [05:43<17:51, 18.80s/it]\u001b[A\n",
            " 25%|██▌       | 19/75 [06:01<17:15, 18.49s/it]\u001b[A\n",
            " 27%|██▋       | 20/75 [06:18<16:35, 18.09s/it]\u001b[A\n",
            " 28%|██▊       | 21/75 [06:35<16:02, 17.83s/it]\u001b[A\n",
            " 29%|██▉       | 22/75 [06:54<15:58, 18.08s/it]\u001b[A\n",
            " 31%|███       | 23/75 [07:11<15:26, 17.83s/it]\u001b[A\n",
            " 32%|███▏      | 24/75 [07:29<14:59, 17.64s/it]\u001b[A\n",
            " 33%|███▎      | 25/75 [07:46<14:39, 17.59s/it]\u001b[A\n",
            " 35%|███▍      | 26/75 [08:03<14:19, 17.54s/it]\u001b[A\n",
            " 36%|███▌      | 27/75 [08:21<13:57, 17.46s/it]\u001b[A\n",
            " 37%|███▋      | 28/75 [08:38<13:35, 17.35s/it]\u001b[A\n",
            " 39%|███▊      | 29/75 [08:55<13:17, 17.34s/it]\u001b[A\n",
            " 40%|████      | 30/75 [09:12<12:56, 17.25s/it]\u001b[A\n",
            " 41%|████▏     | 31/75 [09:30<12:40, 17.29s/it]\u001b[A\n",
            " 43%|████▎     | 32/75 [09:47<12:24, 17.32s/it]\u001b[A\n",
            " 44%|████▍     | 33/75 [10:04<12:08, 17.35s/it]\u001b[A\n",
            " 45%|████▌     | 34/75 [10:21<11:47, 17.26s/it]\u001b[A\n",
            " 47%|████▋     | 35/75 [10:39<11:28, 17.21s/it]\u001b[A\n",
            " 48%|████▊     | 36/75 [10:56<11:09, 17.17s/it]\u001b[A\n",
            " 49%|████▉     | 37/75 [11:13<10:52, 17.17s/it]\u001b[A\n",
            " 51%|█████     | 38/75 [11:30<10:38, 17.25s/it]\u001b[A\n",
            " 52%|█████▏    | 39/75 [11:48<10:23, 17.32s/it]\u001b[A\n",
            " 53%|█████▎    | 40/75 [12:05<10:08, 17.39s/it]\u001b[A\n",
            " 55%|█████▍    | 41/75 [12:23<09:51, 17.40s/it]\u001b[A\n",
            " 56%|█████▌    | 42/75 [12:40<09:32, 17.34s/it]\u001b[A\n",
            " 57%|█████▋    | 43/75 [12:57<09:11, 17.24s/it]\u001b[A\n",
            " 59%|█████▊    | 44/75 [13:14<08:56, 17.30s/it]\u001b[A\n",
            " 60%|██████    | 45/75 [13:31<08:36, 17.21s/it]\u001b[A\n",
            " 61%|██████▏   | 46/75 [13:49<08:20, 17.27s/it]\u001b[A\n",
            " 63%|██████▎   | 47/75 [14:06<08:07, 17.39s/it]\u001b[A\n",
            " 64%|██████▍   | 48/75 [14:24<07:51, 17.46s/it]\u001b[A\n",
            " 65%|██████▌   | 49/75 [14:42<07:34, 17.47s/it]\u001b[A\n",
            " 67%|██████▋   | 50/75 [14:59<07:16, 17.47s/it]\u001b[A\n",
            " 68%|██████▊   | 51/75 [15:16<06:57, 17.41s/it]\u001b[A\n",
            " 69%|██████▉   | 52/75 [15:34<06:39, 17.38s/it]\u001b[A\n",
            " 71%|███████   | 53/75 [15:51<06:22, 17.40s/it]\u001b[A\n",
            " 72%|███████▏  | 54/75 [16:09<06:05, 17.42s/it]\u001b[A\n",
            " 73%|███████▎  | 55/75 [16:26<05:49, 17.46s/it]\u001b[A\n",
            " 75%|███████▍  | 56/75 [16:44<05:31, 17.46s/it]\u001b[A\n",
            " 76%|███████▌  | 57/75 [17:01<05:13, 17.43s/it]\u001b[A\n",
            " 77%|███████▋  | 58/75 [17:18<04:55, 17.39s/it]\u001b[A\n",
            " 79%|███████▊  | 59/75 [17:36<04:38, 17.43s/it]\u001b[A\n",
            " 80%|████████  | 60/75 [17:53<04:21, 17.40s/it]\u001b[A\n",
            " 81%|████████▏ | 61/75 [18:10<04:01, 17.28s/it]\u001b[A\n",
            " 83%|████████▎ | 62/75 [18:27<03:44, 17.26s/it]\u001b[A\n",
            " 84%|████████▍ | 63/75 [18:45<03:27, 17.28s/it]\u001b[A\n",
            " 85%|████████▌ | 64/75 [19:02<03:11, 17.37s/it]\u001b[A\n",
            " 87%|████████▋ | 65/75 [19:19<02:53, 17.35s/it]\u001b[A\n",
            " 88%|████████▊ | 66/75 [19:37<02:35, 17.31s/it]\u001b[A\n",
            " 89%|████████▉ | 67/75 [19:54<02:19, 17.41s/it]\u001b[A\n",
            " 91%|█████████ | 68/75 [20:12<02:02, 17.43s/it]\u001b[A\n",
            " 92%|█████████▏| 69/75 [20:29<01:44, 17.39s/it]\u001b[A\n",
            " 93%|█████████▎| 70/75 [20:47<01:27, 17.50s/it]\u001b[A\n",
            " 95%|█████████▍| 71/75 [21:04<01:09, 17.49s/it]\u001b[A\n",
            " 96%|█████████▌| 72/75 [21:22<00:52, 17.40s/it]\u001b[A\n",
            " 97%|█████████▋| 73/75 [21:39<00:34, 17.35s/it]\u001b[A\n",
            " 99%|█████████▊| 74/75 [21:56<00:17, 17.28s/it]\u001b[A\n",
            "100%|██████████| 75/75 [22:11<00:00, 17.75s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:  0.31591180006663006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 33%|███▎      | 1/3 [25:14<50:29, 1514.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss:  0.18921947479248047\n",
            "Validation Jaccard Score:  0.48732834200797004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/75 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1/75 [00:17<21:23, 17.34s/it]\u001b[A\n",
            "  3%|▎         | 2/75 [00:34<21:18, 17.52s/it]\u001b[A\n",
            "  4%|▍         | 3/75 [00:52<21:01, 17.52s/it]\u001b[A\n",
            "  5%|▌         | 4/75 [01:09<20:37, 17.42s/it]\u001b[A\n",
            "  7%|▋         | 5/75 [01:27<20:21, 17.46s/it]\u001b[A\n",
            "  8%|▊         | 6/75 [01:44<20:07, 17.50s/it]\u001b[A\n",
            "  9%|▉         | 7/75 [02:02<19:48, 17.48s/it]\u001b[A\n",
            " 11%|█         | 8/75 [02:20<19:38, 17.59s/it]\u001b[A\n",
            " 12%|█▏        | 9/75 [02:37<19:22, 17.62s/it]\u001b[A\n",
            " 13%|█▎        | 10/75 [02:55<19:05, 17.63s/it]\u001b[A\n",
            " 15%|█▍        | 11/75 [03:12<18:45, 17.59s/it]\u001b[A\n",
            " 16%|█▌        | 12/75 [03:30<18:25, 17.55s/it]\u001b[A\n",
            " 17%|█▋        | 13/75 [03:47<18:06, 17.53s/it]\u001b[A\n",
            " 19%|█▊        | 14/75 [04:05<17:50, 17.55s/it]\u001b[A\n",
            " 20%|██        | 15/75 [04:22<17:28, 17.47s/it]\u001b[A\n",
            " 21%|██▏       | 16/75 [04:40<17:13, 17.51s/it]\u001b[A\n",
            " 23%|██▎       | 17/75 [04:57<16:56, 17.53s/it]\u001b[A\n",
            " 24%|██▍       | 18/75 [05:15<16:41, 17.57s/it]\u001b[A\n",
            " 25%|██▌       | 19/75 [05:33<16:32, 17.73s/it]\u001b[A\n",
            " 27%|██▋       | 20/75 [05:51<16:18, 17.78s/it]\u001b[A\n",
            " 28%|██▊       | 21/75 [06:09<16:02, 17.83s/it]\u001b[A\n",
            " 29%|██▉       | 22/75 [06:27<15:41, 17.77s/it]\u001b[A\n",
            " 31%|███       | 23/75 [06:44<15:21, 17.73s/it]\u001b[A\n",
            " 32%|███▏      | 24/75 [07:02<15:02, 17.69s/it]\u001b[A\n",
            " 33%|███▎      | 25/75 [07:20<14:43, 17.66s/it]\u001b[A\n",
            " 35%|███▍      | 26/75 [07:37<14:28, 17.72s/it]\u001b[A\n",
            " 36%|███▌      | 27/75 [07:55<14:06, 17.63s/it]\u001b[A\n",
            " 37%|███▋      | 28/75 [08:12<13:49, 17.64s/it]\u001b[A\n",
            " 39%|███▊      | 29/75 [08:30<13:30, 17.63s/it]\u001b[A\n",
            " 40%|████      | 30/75 [08:48<13:15, 17.67s/it]\u001b[A\n",
            " 41%|████▏     | 31/75 [09:05<12:56, 17.65s/it]\u001b[A\n",
            " 43%|████▎     | 32/75 [09:23<12:36, 17.59s/it]\u001b[A\n",
            " 44%|████▍     | 33/75 [09:41<12:20, 17.62s/it]\u001b[A\n",
            " 45%|████▌     | 34/75 [09:58<11:59, 17.54s/it]\u001b[A\n",
            " 47%|████▋     | 35/75 [10:15<11:39, 17.49s/it]\u001b[A\n",
            " 48%|████▊     | 36/75 [10:33<11:22, 17.50s/it]\u001b[A\n",
            " 49%|████▉     | 37/75 [10:50<11:05, 17.52s/it]\u001b[A\n",
            " 51%|█████     | 38/75 [11:08<10:46, 17.47s/it]\u001b[A\n",
            " 52%|█████▏    | 39/75 [11:25<10:28, 17.46s/it]\u001b[A\n",
            " 53%|█████▎    | 40/75 [11:43<10:10, 17.43s/it]\u001b[A\n",
            " 55%|█████▍    | 41/75 [12:00<09:55, 17.50s/it]\u001b[A\n",
            " 56%|█████▌    | 42/75 [12:18<09:41, 17.61s/it]\u001b[A\n",
            " 57%|█████▋    | 43/75 [12:36<09:27, 17.72s/it]\u001b[A\n",
            " 59%|█████▊    | 44/75 [12:54<09:10, 17.76s/it]\u001b[A\n",
            " 60%|██████    | 45/75 [13:12<08:53, 17.79s/it]\u001b[A\n",
            " 61%|██████▏   | 46/75 [13:30<08:36, 17.79s/it]\u001b[A\n",
            " 63%|██████▎   | 47/75 [13:47<08:18, 17.81s/it]\u001b[A\n",
            " 64%|██████▍   | 48/75 [14:05<08:01, 17.84s/it]\u001b[A\n",
            " 65%|██████▌   | 49/75 [14:23<07:44, 17.88s/it]\u001b[A\n",
            " 67%|██████▋   | 50/75 [14:41<07:27, 17.89s/it]\u001b[A\n",
            " 68%|██████▊   | 51/75 [14:59<07:08, 17.85s/it]\u001b[A\n",
            " 69%|██████▉   | 52/75 [15:17<06:50, 17.85s/it]\u001b[A\n",
            " 71%|███████   | 53/75 [15:35<06:33, 17.87s/it]\u001b[A\n",
            " 72%|███████▏  | 54/75 [15:53<06:14, 17.84s/it]\u001b[A\n",
            " 73%|███████▎  | 55/75 [16:10<05:57, 17.87s/it]\u001b[A\n",
            " 75%|███████▍  | 56/75 [16:28<05:39, 17.87s/it]\u001b[A\n",
            " 76%|███████▌  | 57/75 [16:46<05:22, 17.94s/it]\u001b[A\n",
            " 77%|███████▋  | 58/75 [17:04<05:05, 17.97s/it]\u001b[A\n",
            " 79%|███████▊  | 59/75 [17:23<04:48, 18.01s/it]\u001b[A\n",
            " 80%|████████  | 60/75 [17:41<04:30, 18.02s/it]\u001b[A\n",
            " 81%|████████▏ | 61/75 [17:59<04:12, 18.01s/it]\u001b[A\n",
            " 83%|████████▎ | 62/75 [18:17<03:53, 17.99s/it]\u001b[A\n",
            " 84%|████████▍ | 63/75 [18:34<03:35, 17.96s/it]\u001b[A\n",
            " 85%|████████▌ | 64/75 [18:52<03:17, 17.92s/it]\u001b[A\n",
            " 87%|████████▋ | 65/75 [19:10<02:59, 17.98s/it]\u001b[A\n",
            " 88%|████████▊ | 66/75 [19:29<02:42, 18.05s/it]\u001b[A\n",
            " 89%|████████▉ | 67/75 [19:47<02:24, 18.12s/it]\u001b[A\n",
            " 91%|█████████ | 68/75 [20:05<02:06, 18.12s/it]\u001b[A\n",
            " 92%|█████████▏| 69/75 [20:23<01:48, 18.12s/it]\u001b[A\n",
            " 93%|█████████▎| 70/75 [20:41<01:30, 18.15s/it]\u001b[A\n",
            " 95%|█████████▍| 71/75 [21:00<01:12, 18.17s/it]\u001b[A\n",
            " 96%|█████████▌| 72/75 [21:18<00:54, 18.12s/it]\u001b[A\n",
            " 97%|█████████▋| 73/75 [21:36<00:36, 18.08s/it]\u001b[A\n",
            " 99%|█████████▊| 74/75 [21:53<00:17, 17.99s/it]\u001b[A\n",
            "100%|██████████| 75/75 [22:09<00:00, 17.73s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:  0.17159997403621674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 67%|██████▋   | 2/3 [50:32<25:16, 1516.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss:  0.17222631338870886\n",
            "Validation Jaccard Score:  0.5806376112689436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/75 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1/75 [00:18<22:37, 18.35s/it]\u001b[A\n",
            "  3%|▎         | 2/75 [00:36<22:19, 18.35s/it]\u001b[A\n",
            "  4%|▍         | 3/75 [00:54<21:55, 18.27s/it]\u001b[A\n",
            "  5%|▌         | 4/75 [01:13<21:38, 18.28s/it]\u001b[A\n",
            "  7%|▋         | 5/75 [01:31<21:17, 18.25s/it]\u001b[A\n",
            "  8%|▊         | 6/75 [01:49<20:56, 18.21s/it]\u001b[A\n",
            "  9%|▉         | 7/75 [02:07<20:34, 18.16s/it]\u001b[A\n",
            " 11%|█         | 8/75 [02:25<20:12, 18.10s/it]\u001b[A\n",
            " 12%|█▏        | 9/75 [02:43<19:46, 17.97s/it]\u001b[A\n",
            " 13%|█▎        | 10/75 [03:01<19:26, 17.94s/it]\u001b[A\n",
            " 15%|█▍        | 11/75 [03:19<19:09, 17.97s/it]\u001b[A\n",
            " 16%|█▌        | 12/75 [03:37<18:54, 18.00s/it]\u001b[A\n",
            " 17%|█▋        | 13/75 [03:55<18:34, 17.98s/it]\u001b[A\n",
            " 19%|█▊        | 14/75 [04:13<18:19, 18.02s/it]\u001b[A\n",
            " 20%|██        | 15/75 [04:31<18:01, 18.03s/it]\u001b[A\n",
            " 21%|██▏       | 16/75 [04:49<17:42, 18.01s/it]\u001b[A\n",
            " 23%|██▎       | 17/75 [05:07<17:24, 18.01s/it]\u001b[A\n",
            " 24%|██▍       | 18/75 [05:25<17:05, 17.99s/it]\u001b[A\n",
            " 25%|██▌       | 19/75 [05:43<16:50, 18.04s/it]\u001b[A\n",
            " 27%|██▋       | 20/75 [06:01<16:37, 18.14s/it]\u001b[A\n",
            " 28%|██▊       | 21/75 [06:19<16:21, 18.18s/it]\u001b[A\n",
            " 29%|██▉       | 22/75 [06:38<16:04, 18.19s/it]\u001b[A\n",
            " 31%|███       | 23/75 [06:56<15:46, 18.21s/it]\u001b[A\n",
            " 32%|███▏      | 24/75 [07:14<15:28, 18.21s/it]\u001b[A\n",
            " 33%|███▎      | 25/75 [07:33<15:13, 18.26s/it]\u001b[A\n",
            " 35%|███▍      | 26/75 [07:51<14:55, 18.28s/it]\u001b[A\n",
            " 36%|███▌      | 27/75 [08:09<14:35, 18.23s/it]\u001b[A\n",
            " 37%|███▋      | 28/75 [08:27<14:16, 18.21s/it]\u001b[A\n",
            " 39%|███▊      | 29/75 [08:45<13:55, 18.16s/it]\u001b[A\n",
            " 40%|████      | 30/75 [09:03<13:35, 18.12s/it]\u001b[A\n",
            " 41%|████▏     | 31/75 [09:21<13:14, 18.05s/it]\u001b[A\n",
            " 43%|████▎     | 32/75 [09:39<12:53, 17.99s/it]\u001b[A\n",
            " 44%|████▍     | 33/75 [09:57<12:34, 17.97s/it]\u001b[A\n",
            " 45%|████▌     | 34/75 [10:15<12:16, 17.96s/it]\u001b[A\n",
            " 47%|████▋     | 35/75 [10:33<11:57, 17.93s/it]\u001b[A\n",
            " 48%|████▊     | 36/75 [10:50<11:37, 17.88s/it]\u001b[A\n",
            " 49%|████▉     | 37/75 [11:08<11:20, 17.92s/it]\u001b[A\n",
            " 51%|█████     | 38/75 [11:27<11:05, 17.99s/it]\u001b[A\n",
            " 52%|█████▏    | 39/75 [11:45<10:48, 18.01s/it]\u001b[A\n",
            " 53%|█████▎    | 40/75 [12:03<10:32, 18.07s/it]\u001b[A\n",
            " 55%|█████▍    | 41/75 [12:21<10:15, 18.09s/it]\u001b[A\n",
            " 56%|█████▌    | 42/75 [12:39<09:55, 18.05s/it]\u001b[A\n",
            " 57%|█████▋    | 43/75 [12:57<09:37, 18.04s/it]\u001b[A\n",
            " 59%|█████▊    | 44/75 [13:15<09:18, 18.03s/it]\u001b[A\n",
            " 60%|██████    | 45/75 [13:33<08:59, 17.99s/it]\u001b[A\n",
            " 61%|██████▏   | 46/75 [13:51<08:41, 17.98s/it]\u001b[A\n",
            " 63%|██████▎   | 47/75 [14:09<08:23, 17.98s/it]\u001b[A\n",
            " 64%|██████▍   | 48/75 [14:27<08:05, 17.98s/it]\u001b[A\n",
            " 65%|██████▌   | 49/75 [14:45<07:47, 17.99s/it]\u001b[A\n",
            " 67%|██████▋   | 50/75 [15:03<07:31, 18.06s/it]\u001b[A\n",
            " 68%|██████▊   | 51/75 [15:21<07:13, 18.08s/it]\u001b[A\n",
            " 69%|██████▉   | 52/75 [15:40<06:57, 18.17s/it]\u001b[A\n",
            " 71%|███████   | 53/75 [15:58<06:39, 18.16s/it]\u001b[A\n",
            " 72%|███████▏  | 54/75 [16:16<06:21, 18.17s/it]\u001b[A\n",
            " 73%|███████▎  | 55/75 [16:34<06:02, 18.15s/it]\u001b[A\n",
            " 75%|███████▍  | 56/75 [16:52<05:43, 18.09s/it]\u001b[A\n",
            " 76%|███████▌  | 57/75 [17:10<05:25, 18.09s/it]\u001b[A\n",
            " 77%|███████▋  | 58/75 [17:28<05:05, 17.99s/it]\u001b[A\n",
            " 79%|███████▊  | 59/75 [17:45<04:45, 17.87s/it]\u001b[A\n",
            " 80%|████████  | 60/75 [18:03<04:25, 17.73s/it]\u001b[A\n",
            " 81%|████████▏ | 61/75 [18:20<04:06, 17.64s/it]\u001b[A\n",
            " 83%|████████▎ | 62/75 [18:38<03:48, 17.56s/it]\u001b[A\n",
            " 84%|████████▍ | 63/75 [18:55<03:28, 17.39s/it]\u001b[A\n",
            " 85%|████████▌ | 64/75 [19:12<03:10, 17.34s/it]\u001b[A\n",
            " 87%|████████▋ | 65/75 [19:29<02:51, 17.18s/it]\u001b[A\n",
            " 88%|████████▊ | 66/75 [19:46<02:34, 17.12s/it]\u001b[A\n",
            " 89%|████████▉ | 67/75 [20:03<02:17, 17.14s/it]\u001b[A\n",
            " 91%|█████████ | 68/75 [20:20<02:00, 17.20s/it]\u001b[A\n",
            " 92%|█████████▏| 69/75 [20:37<01:43, 17.20s/it]\u001b[A\n",
            " 93%|█████████▎| 70/75 [20:54<01:25, 17.12s/it]\u001b[A\n",
            " 95%|█████████▍| 71/75 [21:11<01:08, 17.09s/it]\u001b[A\n",
            " 96%|█████████▌| 72/75 [21:29<00:51, 17.14s/it]\u001b[A\n",
            " 97%|█████████▋| 73/75 [21:46<00:34, 17.14s/it]\u001b[A\n",
            " 99%|█████████▊| 74/75 [22:03<00:17, 17.15s/it]\u001b[A\n",
            "100%|██████████| 75/75 [22:18<00:00, 17.85s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:  0.1592425079147021\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 3/3 [1:15:44<00:00, 1514.24s/it]"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "\n",
        "for epoch in tqdm(range(3)):\n",
        "  batch_loss = 0\n",
        "  count=0\n",
        "  for batch in tqdm(train_dataloader):\n",
        "    optim.zero_grad()\n",
        "    inputs = batch[0]\n",
        "    attention = batch[1]\n",
        "    labels = batch[2]\n",
        "    outputs = model(inputs, attention_mask = attention, labels=labels)\n",
        "    loss= outputs.loss\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    count+=1\n",
        "    batch_loss += loss.item()\n",
        "  print(\"Loss: \", batch_loss/count)\n",
        "  val_score, val_loss = evaluate(model,test_dataloader)\n",
        "  print(\"Validation Loss: \", val_loss)\n",
        "  print(\"Validation Jaccard Score: \", val_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h10ozbJSV1RA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"/content/trained_model\")\n",
        "model.save_pretrained(\"/content/trained_model\")\n",
        "!zip -r /content/model.zip /content/trained_model\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/model.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA03k6Nkxtmi",
        "outputId": "56643f11-f6c5-4003-d8f6-07050e3397a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss:  0.16753120133371063\n",
            "Validation Jaccard Score:  0.6178570029779169\n"
          ]
        }
      ],
      "source": [
        "val_score, val_loss = evaluate(model,test_dataloader)\n",
        "print(\"Validation Loss: \", val_loss)\n",
        "print(\"Validation Jaccard Score: \", val_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k09a8Lo6JjuN"
      },
      "source": [
        "## Pre-trained RoBERTa model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "15f6b70ae1f74ecb916ee3d76478aac4",
            "ca39a5daada94d0e8480926f13cc5f66",
            "a4c516a72c8f4ef5a357d249a09387fd",
            "8ea6da72f516408bbc91d0eeb53b58dc",
            "e04880628587407caec125f954b6fa32",
            "6acf3c68d6184a04837cf24bf2cb94bc",
            "acb1410b22604405bb39df6874e787a8",
            "7ff253142fd440b1b4a8f20df141d565",
            "edff557bd3f246b89ebe09381a1881f8",
            "8b941cbc2cae425482a3f033b555de96",
            "854c83e787cd4ea795c22f2b1d9c9aa4",
            "aeed034b61e54f9aa8e726ce70ebe0ac",
            "a278e1f13f21412e86f224ac51dd9256",
            "baefbd45994147fa92a746c134420327",
            "52fc72ada16e49e784572c8e6eab371b",
            "5ee71b54d154405c8a095cb9a5f784f3",
            "8e98a1e5eb894bc4a65721fcc07fe8f6",
            "151948a5dc9c4df7a34dc927f52e5079",
            "841045df6c174819af05ddcd6a5c02e6",
            "46182b2df7724202b85a54194ea67dfe",
            "ebfbfb8de8ec4094b50147d7ae4578a7",
            "fca809eda7464f0fbabd2b1334d482a8",
            "063c2c4f824945c29ae74926929a0df8",
            "5096dc8071054cccab9c744d5b14af5a",
            "75d90555de874f14b3d05f212a2fc9ff",
            "c5c4a4d529bc4f3d87a43e51fbe57aa0",
            "251f17a4acc24ec1885fded58ab1499c",
            "68e68ea703304373b8aad61d53008f28",
            "959f29dc357d47cd848281f8152b6471",
            "b89fd22ebe9048678b4fc528245dd51c",
            "ac528520c184457e93466216396c57a0",
            "a4f68d02cb834ebd895e7fdf41959d54",
            "ac13b6dad99547cba2c891c24234de24",
            "ef84c9cdb7d9430da5357fe4659048c7",
            "a9e20f8d46d74b20bc157c461bb62cd0",
            "cd852e5519df4156a7e6bc6614f04c1d",
            "643671c34af8410a8e7485f06140a628",
            "18844d6722124384aa6e59a661d5d28f",
            "2a5cc7f0d06e4fce913a22df25a9d127",
            "501aa57e82ad46fb96d4d6120cc994e7",
            "c888985193e843ceb0c7e31df0299c05",
            "1e1d331ca0164f83b95f8521bbd836cf",
            "587a7d931bea4985a51a17ac5299f4d8",
            "19e88ff4ebca48cf9ea0e8d571aa7536"
          ]
        },
        "id": "gVvksCXZJpxr",
        "outputId": "453c1aa4-98f2-4b26-e392-1a188c06145c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15f6b70ae1f74ecb916ee3d76478aac4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aeed034b61e54f9aa8e726ce70ebe0ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "063c2c4f824945c29ae74926929a0df8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef84c9cdb7d9430da5357fe4659048c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "roberta_model = RobertaForTokenClassification.from_pretrained(\"roberta-base\")\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95zjBmicMvvw",
        "outputId": "7c5fdffc-3aa5-41c5-a5ef-daa14d8b8d76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ],
      "source": [
        "encodings2 = roberta_tokenizer(list(X_train['text']), text_pair=list(X_train['sentiment']), max_length=32, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "test_encodings2 = roberta_tokenizer(list(X_test['text']), text_pair=list(X_test['sentiment']), max_length=32, padding=True, truncation=True,  return_tensors=\"pt\")\n",
        "y_encodings2 = roberta_tokenizer(list(y_train), max_length=32, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "y_test_encodings2 = roberta_tokenizer(list(y_test), max_length=32, padding=True, truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gleaK3AEM0BF"
      },
      "outputs": [],
      "source": [
        "def map_selected_text(text_tensor, selected_text_tensor):\n",
        "  selected = []\n",
        "  \n",
        "  for each in selected_text_tensor:\n",
        "    if each ==101:\n",
        "      continue\n",
        "    if each ==102:\n",
        "      break\n",
        "    selected.append(each)\n",
        "  pos = []\n",
        "  # print(selected)\n",
        "  for each in selected:\n",
        "    pos.append((text_tensor == each).nonzero().flatten())\n",
        "  ret = torch.zeros(text_tensor.shape[0])\n",
        "  for each in pos:\n",
        "    ret[each] = 1\n",
        "\n",
        "  return ret\n",
        "\n",
        "\n",
        "map_selected_text(encodings2[\"input_ids\"][1], y_encodings2[\"input_ids\"][1])\n",
        "train_labels2 = []\n",
        "test_labels2 = []\n",
        "\n",
        "for i in range(len(encodings2[\"input_ids\"])):\n",
        "  train_labels2.append(map_selected_text(encodings2[\"input_ids\"][i], y_encodings2[\"input_ids\"][i]))\n",
        "\n",
        "for i in range(len(test_encodings[\"input_ids\"])):\n",
        "  test_labels2.append(map_selected_text(test_encodings2[\"input_ids\"][i], y_test_encodings2[\"input_ids\"][i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftEZXaJBNQ-l"
      },
      "outputs": [],
      "source": [
        "train_labels2 = torch.stack(train_labels2).long()\n",
        "test_labels2 = torch.stack(test_labels2).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWSAFNTONWtT"
      },
      "outputs": [],
      "source": [
        "train_dataset2 = OurDataset(encodings2, train_labels2)\n",
        "train_dataloader2 = torch.utils.data.DataLoader(train_dataset2, batch_size=64, shuffle=True)\n",
        "test_dataset2 = OurDataset(test_encodings2, test_labels2)\n",
        "test_dataloader2 = torch.utils.data.DataLoader(test_dataset2, batch_size=64, shuffle=False)\n",
        "\n",
        "optim2 = torch.optim.AdamW(roberta_model.parameters(), lr=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iov69tMUIby6"
      },
      "source": [
        "## 4.2 RoBERTa Architecture and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGwGUQwaJKUV",
        "outputId": "a4e3765b-411e-4752-e4a5-91d5c5c6b845"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "  0%|          | 0/75 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1/75 [00:23<28:52, 23.42s/it]\u001b[A\n",
            "  3%|▎         | 2/75 [00:42<25:21, 20.84s/it]\u001b[A\n",
            "  4%|▍         | 3/75 [01:06<26:40, 22.23s/it]\u001b[A\n",
            "  5%|▌         | 4/75 [01:28<26:05, 22.05s/it]\u001b[A\n",
            "  7%|▋         | 5/75 [01:45<23:35, 20.23s/it]\u001b[A\n",
            "  8%|▊         | 6/75 [02:02<22:02, 19.16s/it]\u001b[A\n",
            "  9%|▉         | 7/75 [02:19<20:59, 18.51s/it]\u001b[A\n",
            " 11%|█         | 8/75 [02:36<20:07, 18.03s/it]\u001b[A\n",
            " 12%|█▏        | 9/75 [02:54<19:46, 17.98s/it]\u001b[A\n",
            " 13%|█▎        | 10/75 [03:11<19:14, 17.76s/it]\u001b[A\n",
            " 15%|█▍        | 11/75 [03:28<18:44, 17.58s/it]\u001b[A\n",
            " 16%|█▌        | 12/75 [03:45<18:20, 17.47s/it]\u001b[A\n",
            " 17%|█▋        | 13/75 [04:03<17:58, 17.39s/it]\u001b[A\n",
            " 19%|█▊        | 14/75 [04:20<17:35, 17.30s/it]\u001b[A\n",
            " 20%|██        | 15/75 [04:39<18:02, 18.04s/it]\u001b[A\n",
            " 21%|██▏       | 16/75 [04:56<17:22, 17.67s/it]\u001b[A\n",
            " 23%|██▎       | 17/75 [05:13<16:41, 17.27s/it]\u001b[A\n",
            " 24%|██▍       | 18/75 [05:29<16:14, 17.10s/it]\u001b[A\n",
            " 25%|██▌       | 19/75 [05:46<15:49, 16.95s/it]\u001b[A\n",
            " 27%|██▋       | 20/75 [06:03<15:30, 16.92s/it]\u001b[A\n",
            " 28%|██▊       | 21/75 [06:20<15:18, 17.00s/it]\u001b[A\n",
            " 29%|██▉       | 22/75 [06:38<15:14, 17.25s/it]\u001b[A\n",
            " 31%|███       | 23/75 [06:56<15:04, 17.39s/it]\u001b[A\n",
            " 32%|███▏      | 24/75 [07:14<14:55, 17.57s/it]\u001b[A\n",
            " 33%|███▎      | 25/75 [07:31<14:32, 17.46s/it]\u001b[A\n",
            " 35%|███▍      | 26/75 [07:47<14:03, 17.22s/it]\u001b[A\n",
            " 36%|███▌      | 27/75 [08:04<13:38, 17.05s/it]\u001b[A\n",
            " 37%|███▋      | 28/75 [08:21<13:20, 17.04s/it]\u001b[A\n",
            " 39%|███▊      | 29/75 [08:39<13:13, 17.24s/it]\u001b[A\n",
            " 40%|████      | 30/75 [08:56<12:56, 17.25s/it]\u001b[A\n",
            " 41%|████▏     | 31/75 [09:13<12:35, 17.17s/it]\u001b[A\n",
            " 43%|████▎     | 32/75 [09:30<12:17, 17.16s/it]\u001b[A\n",
            " 44%|████▍     | 33/75 [09:47<11:59, 17.13s/it]\u001b[A\n",
            " 45%|████▌     | 34/75 [10:04<11:42, 17.13s/it]\u001b[A\n",
            " 47%|████▋     | 35/75 [10:21<11:24, 17.10s/it]\u001b[A\n",
            " 48%|████▊     | 36/75 [10:38<11:01, 16.97s/it]\u001b[A\n",
            " 49%|████▉     | 37/75 [10:55<10:40, 16.86s/it]\u001b[A\n",
            " 51%|█████     | 38/75 [11:12<10:30, 17.04s/it]\u001b[A\n",
            " 52%|█████▏    | 39/75 [11:30<10:19, 17.20s/it]\u001b[A\n",
            " 53%|█████▎    | 40/75 [11:47<10:06, 17.32s/it]\u001b[A\n",
            " 55%|█████▍    | 41/75 [12:04<09:46, 17.26s/it]\u001b[A\n",
            " 56%|█████▌    | 42/75 [12:22<09:28, 17.23s/it]\u001b[A\n",
            " 57%|█████▋    | 43/75 [12:39<09:09, 17.16s/it]\u001b[A\n",
            " 59%|█████▊    | 44/75 [12:55<08:47, 17.03s/it]\u001b[A\n",
            " 60%|██████    | 45/75 [13:12<08:25, 16.85s/it]\u001b[A\n",
            " 61%|██████▏   | 46/75 [13:28<08:06, 16.79s/it]\u001b[A\n",
            " 63%|██████▎   | 47/75 [13:45<07:51, 16.85s/it]\u001b[A\n",
            " 64%|██████▍   | 48/75 [14:03<07:38, 16.97s/it]\u001b[A\n",
            " 65%|██████▌   | 49/75 [14:19<07:17, 16.84s/it]\u001b[A\n",
            " 67%|██████▋   | 50/75 [14:36<06:58, 16.75s/it]\u001b[A\n",
            " 68%|██████▊   | 51/75 [14:52<06:42, 16.76s/it]\u001b[A\n",
            " 69%|██████▉   | 52/75 [15:09<06:26, 16.79s/it]\u001b[A\n",
            " 71%|███████   | 53/75 [15:26<06:10, 16.83s/it]\u001b[A\n",
            " 72%|███████▏  | 54/75 [15:43<05:52, 16.78s/it]\u001b[A\n",
            " 73%|███████▎  | 55/75 [15:59<05:34, 16.71s/it]\u001b[A\n",
            " 75%|███████▍  | 56/75 [16:16<05:17, 16.70s/it]\u001b[A\n",
            " 76%|███████▌  | 57/75 [16:33<05:00, 16.69s/it]\u001b[A\n",
            " 77%|███████▋  | 58/75 [16:49<04:42, 16.63s/it]\u001b[A\n",
            " 79%|███████▊  | 59/75 [17:06<04:28, 16.77s/it]\u001b[A\n",
            " 80%|████████  | 60/75 [17:23<04:11, 16.76s/it]\u001b[A\n",
            " 81%|████████▏ | 61/75 [17:40<03:55, 16.85s/it]\u001b[A\n",
            " 83%|████████▎ | 62/75 [17:57<03:40, 16.97s/it]\u001b[A\n",
            " 84%|████████▍ | 63/75 [18:15<03:25, 17.11s/it]\u001b[A\n",
            " 85%|████████▌ | 64/75 [18:33<03:10, 17.29s/it]\u001b[A\n",
            " 87%|████████▋ | 65/75 [18:50<02:53, 17.30s/it]\u001b[A\n",
            " 88%|████████▊ | 66/75 [19:07<02:34, 17.13s/it]\u001b[A\n",
            " 89%|████████▉ | 67/75 [19:23<02:15, 16.93s/it]\u001b[A\n",
            " 91%|█████████ | 68/75 [19:40<01:58, 16.96s/it]\u001b[A\n",
            " 92%|█████████▏| 69/75 [19:57<01:41, 16.98s/it]\u001b[A\n",
            " 93%|█████████▎| 70/75 [20:14<01:25, 17.02s/it]\u001b[A\n",
            " 95%|█████████▍| 71/75 [20:31<01:07, 16.99s/it]\u001b[A\n",
            " 96%|█████████▌| 72/75 [20:49<00:51, 17.08s/it]\u001b[A\n",
            " 97%|█████████▋| 73/75 [21:06<00:34, 17.17s/it]\u001b[A\n",
            " 99%|█████████▊| 74/75 [21:23<00:17, 17.14s/it]\u001b[A\n",
            "100%|██████████| 75/75 [21:38<00:00, 17.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:  0.4199302005767822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 1/3 [24:35<49:11, 1475.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss:  0.3483509583906694\n",
            "Validation Jaccard Score:  0.72183036739435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/75 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1/75 [00:17<21:39, 17.56s/it]\u001b[A\n",
            "  3%|▎         | 2/75 [00:35<21:38, 17.78s/it]\u001b[A\n",
            "  4%|▍         | 3/75 [00:53<21:11, 17.65s/it]\u001b[A\n",
            "  5%|▌         | 4/75 [01:10<20:48, 17.59s/it]\u001b[A\n",
            "  7%|▋         | 5/75 [01:28<20:32, 17.60s/it]\u001b[A\n",
            "  8%|▊         | 6/75 [01:45<20:12, 17.57s/it]\u001b[A\n",
            "  9%|▉         | 7/75 [02:03<20:05, 17.72s/it]\u001b[A\n",
            " 11%|█         | 8/75 [02:21<19:52, 17.80s/it]\u001b[A\n",
            " 12%|█▏        | 9/75 [02:39<19:32, 17.76s/it]\u001b[A\n",
            " 13%|█▎        | 10/75 [02:57<19:18, 17.82s/it]\u001b[A\n",
            " 15%|█▍        | 11/75 [03:15<19:04, 17.88s/it]\u001b[A\n",
            " 16%|█▌        | 12/75 [03:32<18:42, 17.82s/it]\u001b[A\n",
            " 17%|█▋        | 13/75 [03:50<18:26, 17.85s/it]\u001b[A\n",
            " 19%|█▊        | 14/75 [04:08<18:04, 17.77s/it]\u001b[A\n",
            " 20%|██        | 15/75 [04:25<17:41, 17.69s/it]\u001b[A\n",
            " 21%|██▏       | 16/75 [04:43<17:21, 17.65s/it]\u001b[A\n",
            " 23%|██▎       | 17/75 [05:01<17:02, 17.64s/it]\u001b[A\n",
            " 24%|██▍       | 18/75 [05:19<16:50, 17.72s/it]\u001b[A\n",
            " 25%|██▌       | 19/75 [05:37<16:38, 17.83s/it]\u001b[A\n",
            " 27%|██▋       | 20/75 [05:55<16:30, 18.01s/it]\u001b[A\n",
            " 28%|██▊       | 21/75 [06:13<16:16, 18.08s/it]\u001b[A\n",
            " 29%|██▉       | 22/75 [06:31<15:50, 17.94s/it]\u001b[A\n",
            " 31%|███       | 23/75 [06:48<15:23, 17.76s/it]\u001b[A\n",
            " 32%|███▏      | 24/75 [07:05<14:55, 17.56s/it]\u001b[A\n",
            " 33%|███▎      | 25/75 [07:22<14:29, 17.40s/it]\u001b[A\n",
            " 35%|███▍      | 26/75 [07:40<14:08, 17.32s/it]\u001b[A\n",
            " 36%|███▌      | 27/75 [07:57<13:54, 17.39s/it]\u001b[A\n",
            " 37%|███▋      | 28/75 [08:14<13:34, 17.34s/it]\u001b[A\n",
            " 39%|███▊      | 29/75 [08:31<13:15, 17.29s/it]\u001b[A\n",
            " 40%|████      | 30/75 [08:48<12:52, 17.17s/it]\u001b[A\n",
            " 41%|████▏     | 31/75 [09:05<12:30, 17.05s/it]\u001b[A\n",
            " 43%|████▎     | 32/75 [09:22<12:14, 17.09s/it]\u001b[A\n",
            " 44%|████▍     | 33/75 [09:39<11:57, 17.08s/it]\u001b[A\n",
            " 45%|████▌     | 34/75 [09:56<11:40, 17.09s/it]\u001b[A\n",
            " 47%|████▋     | 35/75 [10:14<11:24, 17.12s/it]\u001b[A\n",
            " 48%|████▊     | 36/75 [10:31<11:09, 17.16s/it]\u001b[A\n",
            " 49%|████▉     | 37/75 [10:49<10:58, 17.33s/it]\u001b[A\n",
            " 51%|█████     | 38/75 [11:06<10:46, 17.48s/it]\u001b[A\n",
            " 52%|█████▏    | 39/75 [11:25<10:36, 17.68s/it]\u001b[A\n",
            " 53%|█████▎    | 40/75 [11:43<10:23, 17.80s/it]\u001b[A\n",
            " 55%|█████▍    | 41/75 [12:01<10:06, 17.85s/it]\u001b[A\n",
            " 56%|█████▌    | 42/75 [12:19<09:49, 17.86s/it]\u001b[A\n",
            " 57%|█████▋    | 43/75 [12:37<09:32, 17.90s/it]\u001b[A\n",
            " 59%|█████▊    | 44/75 [12:55<09:16, 17.94s/it]\u001b[A\n",
            " 60%|██████    | 45/75 [13:13<09:00, 18.00s/it]\u001b[A\n",
            " 61%|██████▏   | 46/75 [13:31<08:41, 17.98s/it]\u001b[A\n",
            " 63%|██████▎   | 47/75 [13:49<08:24, 18.00s/it]\u001b[A\n",
            " 64%|██████▍   | 48/75 [14:07<08:06, 18.03s/it]\u001b[A\n",
            " 65%|██████▌   | 49/75 [14:25<07:49, 18.06s/it]\u001b[A\n",
            " 67%|██████▋   | 50/75 [14:43<07:32, 18.11s/it]\u001b[A\n",
            " 68%|██████▊   | 51/75 [15:01<07:13, 18.06s/it]\u001b[A\n",
            " 69%|██████▉   | 52/75 [15:19<06:55, 18.05s/it]\u001b[A\n",
            " 71%|███████   | 53/75 [15:37<06:38, 18.10s/it]\u001b[A\n",
            " 72%|███████▏  | 54/75 [15:55<06:19, 18.06s/it]\u001b[A\n",
            " 73%|███████▎  | 55/75 [16:13<06:01, 18.06s/it]\u001b[A\n",
            " 75%|███████▍  | 56/75 [16:31<05:40, 17.94s/it]\u001b[A\n",
            " 76%|███████▌  | 57/75 [16:48<05:20, 17.79s/it]\u001b[A\n",
            " 77%|███████▋  | 58/75 [17:06<05:01, 17.76s/it]\u001b[A\n",
            " 79%|███████▊  | 59/75 [17:24<04:43, 17.70s/it]\u001b[A\n",
            " 80%|████████  | 60/75 [17:42<04:26, 17.77s/it]\u001b[A\n",
            " 81%|████████▏ | 61/75 [18:00<04:10, 17.89s/it]\u001b[A\n",
            " 83%|████████▎ | 62/75 [18:18<03:54, 18.03s/it]\u001b[A\n",
            " 84%|████████▍ | 63/75 [18:36<03:35, 17.99s/it]\u001b[A\n",
            " 85%|████████▌ | 64/75 [18:54<03:18, 18.03s/it]\u001b[A\n",
            " 87%|████████▋ | 65/75 [19:12<03:00, 18.03s/it]\u001b[A\n",
            " 88%|████████▊ | 66/75 [19:30<02:42, 18.06s/it]\u001b[A\n",
            " 89%|████████▉ | 67/75 [19:49<02:24, 18.10s/it]\u001b[A\n",
            " 91%|█████████ | 68/75 [20:07<02:06, 18.10s/it]\u001b[A\n",
            " 92%|█████████▏| 69/75 [20:25<01:49, 18.20s/it]\u001b[A\n",
            " 93%|█████████▎| 70/75 [20:43<01:31, 18.25s/it]\u001b[A\n",
            " 95%|█████████▍| 71/75 [21:02<01:13, 18.32s/it]\u001b[A\n",
            " 96%|█████████▌| 72/75 [21:20<00:55, 18.37s/it]\u001b[A\n",
            " 97%|█████████▋| 73/75 [21:39<00:36, 18.37s/it]\u001b[A\n",
            " 99%|█████████▊| 74/75 [21:57<00:18, 18.39s/it]\u001b[A\n",
            "100%|██████████| 75/75 [22:13<00:00, 17.78s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:  0.2739994251728058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 2/3 [49:50<24:58, 1498.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss:  0.22490169062758936\n",
            "Validation Jaccard Score:  0.8787439355596516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/75 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1/75 [00:18<22:32, 18.28s/it]\u001b[A\n",
            "  3%|▎         | 2/75 [00:36<22:09, 18.21s/it]\u001b[A\n",
            "  4%|▍         | 3/75 [00:54<21:42, 18.09s/it]\u001b[A\n",
            "  5%|▌         | 4/75 [01:12<21:24, 18.09s/it]\u001b[A\n",
            "  7%|▋         | 5/75 [01:30<21:03, 18.05s/it]\u001b[A\n",
            "  8%|▊         | 6/75 [01:48<20:44, 18.03s/it]\u001b[A\n",
            "  9%|▉         | 7/75 [02:06<20:27, 18.05s/it]\u001b[A\n",
            " 11%|█         | 8/75 [02:24<20:06, 18.01s/it]\u001b[A\n",
            " 12%|█▏        | 9/75 [02:42<19:55, 18.11s/it]\u001b[A\n",
            " 13%|█▎        | 10/75 [03:01<19:42, 18.19s/it]\u001b[A\n",
            " 15%|█▍        | 11/75 [03:19<19:25, 18.21s/it]\u001b[A\n",
            " 16%|█▌        | 12/75 [03:37<19:07, 18.21s/it]\u001b[A\n",
            " 17%|█▋        | 13/75 [03:55<18:49, 18.22s/it]\u001b[A\n",
            " 19%|█▊        | 14/75 [04:13<18:27, 18.16s/it]\u001b[A\n",
            " 20%|██        | 15/75 [04:31<18:07, 18.12s/it]\u001b[A\n",
            " 21%|██▏       | 16/75 [04:49<17:46, 18.07s/it]\u001b[A\n",
            " 23%|██▎       | 17/75 [05:08<17:32, 18.14s/it]\u001b[A\n",
            " 24%|██▍       | 18/75 [05:26<17:13, 18.12s/it]\u001b[A\n",
            " 25%|██▌       | 19/75 [05:44<16:54, 18.11s/it]\u001b[A\n",
            " 27%|██▋       | 20/75 [06:02<16:40, 18.20s/it]\u001b[A\n",
            " 28%|██▊       | 21/75 [06:21<16:31, 18.36s/it]\u001b[A\n",
            " 29%|██▉       | 22/75 [06:40<16:16, 18.42s/it]\u001b[A\n",
            " 31%|███       | 23/75 [06:58<15:57, 18.42s/it]\u001b[A\n",
            " 32%|███▏      | 24/75 [07:16<15:37, 18.38s/it]\u001b[A\n",
            " 33%|███▎      | 25/75 [07:35<15:18, 18.37s/it]\u001b[A\n",
            " 35%|███▍      | 26/75 [07:53<14:58, 18.34s/it]\u001b[A\n",
            " 36%|███▌      | 27/75 [08:11<14:38, 18.30s/it]\u001b[A\n",
            " 37%|███▋      | 28/75 [08:29<14:16, 18.23s/it]\u001b[A\n",
            " 39%|███▊      | 29/75 [08:47<13:56, 18.19s/it]\u001b[A\n",
            " 40%|████      | 30/75 [09:06<13:39, 18.22s/it]\u001b[A\n",
            " 41%|████▏     | 31/75 [09:24<13:26, 18.34s/it]\u001b[A\n",
            " 43%|████▎     | 32/75 [09:43<13:10, 18.39s/it]\u001b[A\n",
            " 44%|████▍     | 33/75 [10:01<12:54, 18.43s/it]\u001b[A\n",
            " 45%|████▌     | 34/75 [10:19<12:32, 18.36s/it]\u001b[A\n",
            " 47%|████▋     | 35/75 [10:37<12:11, 18.28s/it]\u001b[A\n",
            " 48%|████▊     | 36/75 [10:55<11:49, 18.20s/it]\u001b[A\n",
            " 49%|████▉     | 37/75 [11:13<11:29, 18.13s/it]\u001b[A\n",
            " 51%|█████     | 38/75 [11:32<11:15, 18.25s/it]\u001b[A\n",
            " 52%|█████▏    | 39/75 [11:51<10:59, 18.33s/it]\u001b[A\n",
            " 53%|█████▎    | 40/75 [12:09<10:43, 18.37s/it]\u001b[A\n",
            " 55%|█████▍    | 41/75 [12:27<10:24, 18.37s/it]\u001b[A\n",
            " 56%|█████▌    | 42/75 [12:46<10:05, 18.35s/it]\u001b[A\n",
            " 57%|█████▋    | 43/75 [13:04<09:48, 18.39s/it]\u001b[A\n",
            " 59%|█████▊    | 44/75 [13:23<09:31, 18.43s/it]\u001b[A\n",
            " 60%|██████    | 45/75 [13:41<09:10, 18.36s/it]\u001b[A\n",
            " 61%|██████▏   | 46/75 [13:59<08:51, 18.34s/it]\u001b[A\n",
            " 63%|██████▎   | 47/75 [14:18<08:33, 18.35s/it]\u001b[A\n",
            " 64%|██████▍   | 48/75 [14:36<08:17, 18.44s/it]\u001b[A\n",
            " 65%|██████▌   | 49/75 [14:55<08:01, 18.51s/it]\u001b[A\n",
            " 67%|██████▋   | 50/75 [15:13<07:41, 18.47s/it]\u001b[A\n",
            " 68%|██████▊   | 51/75 [15:31<07:21, 18.39s/it]\u001b[A\n",
            " 69%|██████▉   | 52/75 [15:50<07:00, 18.30s/it]\u001b[A\n",
            " 71%|███████   | 53/75 [16:08<06:43, 18.32s/it]\u001b[A\n",
            " 72%|███████▏  | 54/75 [16:26<06:23, 18.25s/it]\u001b[A\n",
            " 73%|███████▎  | 55/75 [16:44<06:04, 18.22s/it]\u001b[A\n",
            " 75%|███████▍  | 56/75 [17:02<05:45, 18.20s/it]\u001b[A\n",
            " 76%|███████▌  | 57/75 [17:20<05:26, 18.14s/it]\u001b[A\n",
            " 77%|███████▋  | 58/75 [17:39<05:10, 18.25s/it]\u001b[A\n",
            " 79%|███████▊  | 59/75 [17:57<04:51, 18.25s/it]\u001b[A\n",
            " 80%|████████  | 60/75 [18:15<04:33, 18.26s/it]\u001b[A\n",
            " 81%|████████▏ | 61/75 [18:34<04:16, 18.29s/it]\u001b[A\n",
            " 83%|████████▎ | 62/75 [18:52<03:58, 18.35s/it]\u001b[A\n",
            " 84%|████████▍ | 63/75 [19:11<03:40, 18.36s/it]\u001b[A\n",
            " 85%|████████▌ | 64/75 [19:29<03:21, 18.32s/it]\u001b[A\n",
            " 87%|████████▋ | 65/75 [19:47<03:02, 18.25s/it]\u001b[A\n",
            " 88%|████████▊ | 66/75 [20:05<02:43, 18.21s/it]\u001b[A\n",
            " 89%|████████▉ | 67/75 [20:23<02:25, 18.15s/it]\u001b[A\n",
            " 91%|█████████ | 68/75 [20:41<02:06, 18.07s/it]\u001b[A\n",
            " 92%|█████████▏| 69/75 [20:59<01:48, 18.01s/it]\u001b[A\n",
            " 93%|█████████▎| 70/75 [21:17<01:29, 17.99s/it]\u001b[A\n",
            " 95%|█████████▍| 71/75 [21:35<01:11, 17.96s/it]\u001b[A\n",
            " 96%|█████████▌| 72/75 [21:53<00:53, 17.98s/it]\u001b[A\n",
            " 97%|█████████▋| 73/75 [22:11<00:36, 18.09s/it]\u001b[A\n",
            " 99%|█████████▊| 74/75 [22:29<00:18, 18.13s/it]\u001b[A\n",
            "100%|██████████| 75/75 [22:45<00:00, 18.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:  0.21279972652594248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 3/3 [1:15:42<00:00, 1522.99s/it]"
          ]
        }
      ],
      "source": [
        "roberta_model.train()\n",
        "\n",
        "for epoch in tqdm(range(3)):\n",
        "  batch_loss = 0\n",
        "  count=0\n",
        "  for batch in tqdm(train_dataloader2):\n",
        "    optim2.zero_grad()\n",
        "    inputs = batch[0]\n",
        "    attention = batch[1]\n",
        "    labels = batch[2]\n",
        "    outputs = roberta_model(inputs, attention_mask = attention, labels=labels)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optim2.step()\n",
        "    count += 1\n",
        "    batch_loss += loss.item()\n",
        "  print(\"Loss: \", batch_loss/count)\n",
        "  val_score, val_loss = evaluate(roberta_model,test_dataloader2)\n",
        "  print(\"Validation Loss: \", val_loss)\n",
        "  print(\"Validation Jaccard Score: \", val_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plEg91oYzf8t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# os.makedirs(\"/content/trained_roberta_model\")\n",
        "model.save_pretrained(\"/content/trained_roberta_model\")\n",
        "!zip -r /content/trained_roberta_model.zip /content/trained_roberta_model\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/roberta_model.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8oY7WKaHFnyo",
        "outputId": "e8a76707-672d-4f51-a6f5-9633cf25fb41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss:  0.21435484741673325\n",
            "Validation Jaccard Score:  0.8809196669484296\n"
          ]
        }
      ],
      "source": [
        "  val_score, val_loss = evaluate(roberta_model,test_dataloader2)\n",
        "  print(\"Validation Loss: \", val_loss)\n",
        "  print(\"Validation Jaccard Score: \", val_score)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "j1hq2Lf7Qldw",
        "BZC40u8ZjdYH",
        "DE3qZD6yVOWZ",
        "X48a4mytqE6i",
        "m_Dr4vu0qTf_",
        "OXTU9m7fWGYk",
        "HZODANwSBV8F",
        "PgZY_rqsauJn"
      ],
      "name": "CIS519 final project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "017d33c4d33c46868e5cc1bd48302356": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eae671af63674b4eb483cf7f8ff803b2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cde0e0432e5e48c29f9017693f0b3de0",
            "value": 570
          }
        },
        "063c2c4f824945c29ae74926929a0df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5096dc8071054cccab9c744d5b14af5a",
              "IPY_MODEL_75d90555de874f14b3d05f212a2fc9ff",
              "IPY_MODEL_c5c4a4d529bc4f3d87a43e51fbe57aa0"
            ],
            "layout": "IPY_MODEL_251f17a4acc24ec1885fded58ab1499c"
          }
        },
        "0f9cacde8d4b45749cd223ff5214b270": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "151948a5dc9c4df7a34dc927f52e5079": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15f6b70ae1f74ecb916ee3d76478aac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca39a5daada94d0e8480926f13cc5f66",
              "IPY_MODEL_a4c516a72c8f4ef5a357d249a09387fd",
              "IPY_MODEL_8ea6da72f516408bbc91d0eeb53b58dc"
            ],
            "layout": "IPY_MODEL_e04880628587407caec125f954b6fa32"
          }
        },
        "18844d6722124384aa6e59a661d5d28f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e88ff4ebca48cf9ea0e8d571aa7536": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e1d331ca0164f83b95f8521bbd836cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "251f17a4acc24ec1885fded58ab1499c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29369daf87134f29a1aa7227b420d33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0edf25d82194d95b66d2e3a0a68d31e",
              "IPY_MODEL_d3e75ffce65a4defbcbec0c5fbeb68ac",
              "IPY_MODEL_bd9c6297bf07477d95fc7947c4d1d61f"
            ],
            "layout": "IPY_MODEL_fa1e04ed28304200b628d77f47b7b69c"
          }
        },
        "2a5cc7f0d06e4fce913a22df25a9d127": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ae7d96cf8a24cbd9f1ddae5e380f29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ce364cebe2b414185514128bbd90ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "306f8e838a014233938142fd35bda880": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b45bddf9a584feea35e2fe74f6f8bc1",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a40265798fc4316ad80fd205eeeaf66",
            "value": 231508
          }
        },
        "37245d607fa045c583e7bd1c3eecf4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38de644afe5d42e0ae3e98c74e816c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c96e91e9a4d4baca1e0c968826e87e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa659a3560b4f65b41560ba6e626bcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46182b2df7724202b85a54194ea67dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46763a55a76d40bfb23a411b03871fce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48efa3450cce4769a2ee4bdc5029f57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb09cc12a4874e6381ed0febf28cb216",
            "placeholder": "​",
            "style": "IPY_MODEL_90401b4c62e6439f8e78e184c06b1fbb",
            "value": " 226k/226k [00:00&lt;00:00, 312kB/s]"
          }
        },
        "4aa634def35b4d4cb0f666cc919336d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b4e0a4860c145e3b64acc3f6bf5e186": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f0bfb58fb194edb8406583a8f1a5140": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "501aa57e82ad46fb96d4d6120cc994e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5096dc8071054cccab9c744d5b14af5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68e68ea703304373b8aad61d53008f28",
            "placeholder": "​",
            "style": "IPY_MODEL_959f29dc357d47cd848281f8152b6471",
            "value": "Downloading: 100%"
          }
        },
        "52fc72ada16e49e784572c8e6eab371b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebfbfb8de8ec4094b50147d7ae4578a7",
            "placeholder": "​",
            "style": "IPY_MODEL_fca809eda7464f0fbabd2b1334d482a8",
            "value": " 478M/478M [00:13&lt;00:00, 24.5MB/s]"
          }
        },
        "55ee5bfaea0e477f9f046f91b977e23f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56eb19a571a04d3c9a8de8167a9b31d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d27ae94556c4ace83b234a0866a9967",
              "IPY_MODEL_306f8e838a014233938142fd35bda880",
              "IPY_MODEL_48efa3450cce4769a2ee4bdc5029f57d"
            ],
            "layout": "IPY_MODEL_64f6cc4747544b6ea9aeeb006a461806"
          }
        },
        "587a7d931bea4985a51a17ac5299f4d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a40265798fc4316ad80fd205eeeaf66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b45bddf9a584feea35e2fe74f6f8bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d27ae94556c4ace83b234a0866a9967": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5985cc269824b1d9b1da22ec14dabe9",
            "placeholder": "​",
            "style": "IPY_MODEL_4f0bfb58fb194edb8406583a8f1a5140",
            "value": "Downloading: 100%"
          }
        },
        "5ee71b54d154405c8a095cb9a5f784f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6156cc960aa24aaba6ec1691672d9f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fa659a3560b4f65b41560ba6e626bcf",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ce364cebe2b414185514128bbd90ccd",
            "value": 28
          }
        },
        "643671c34af8410a8e7485f06140a628": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_587a7d931bea4985a51a17ac5299f4d8",
            "placeholder": "​",
            "style": "IPY_MODEL_19e88ff4ebca48cf9ea0e8d571aa7536",
            "value": " 446k/446k [00:00&lt;00:00, 620kB/s]"
          }
        },
        "64f6cc4747544b6ea9aeeb006a461806": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68e68ea703304373b8aad61d53008f28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "694eb34475b546eba7a3823cdd8b438d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd29cc33f3cb4e5195263e0a0b82af67",
            "placeholder": "​",
            "style": "IPY_MODEL_38de644afe5d42e0ae3e98c74e816c74",
            "value": "Downloading: 100%"
          }
        },
        "6acf3c68d6184a04837cf24bf2cb94bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6df015ed8c5d47e981e4b992f7a53e94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d90555de874f14b3d05f212a2fc9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b89fd22ebe9048678b4fc528245dd51c",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac528520c184457e93466216396c57a0",
            "value": 898823
          }
        },
        "773d45ac413040c0a662257990601b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f9cacde8d4b45749cd223ff5214b270",
            "placeholder": "​",
            "style": "IPY_MODEL_91b784d8a9604ee2b962f81cd08d54c0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 274B/s]"
          }
        },
        "7ff253142fd440b1b4a8f20df141d565": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "841045df6c174819af05ddcd6a5c02e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84abb2c467414a8191bcb1e8e1c4dc08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "854c83e787cd4ea795c22f2b1d9c9aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b941cbc2cae425482a3f033b555de96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e98a1e5eb894bc4a65721fcc07fe8f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ea6da72f516408bbc91d0eeb53b58dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b941cbc2cae425482a3f033b555de96",
            "placeholder": "​",
            "style": "IPY_MODEL_854c83e787cd4ea795c22f2b1d9c9aa4",
            "value": " 481/481 [00:00&lt;00:00, 10.7kB/s]"
          }
        },
        "90401b4c62e6439f8e78e184c06b1fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90986fb49951441582e8cf8c3c1e085d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "910de5f313ab4502aa2e8eb2961a2ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c96e91e9a4d4baca1e0c968826e87e5",
            "placeholder": "​",
            "style": "IPY_MODEL_2ae7d96cf8a24cbd9f1ddae5e380f29e",
            "value": " 570/570 [00:00&lt;00:00, 3.79kB/s]"
          }
        },
        "91b784d8a9604ee2b962f81cd08d54c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9560c45379ab4c8ea59aed294bd8a326": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "959f29dc357d47cd848281f8152b6471": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a278e1f13f21412e86f224ac51dd9256": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e98a1e5eb894bc4a65721fcc07fe8f6",
            "placeholder": "​",
            "style": "IPY_MODEL_151948a5dc9c4df7a34dc927f52e5079",
            "value": "Downloading: 100%"
          }
        },
        "a4c516a72c8f4ef5a357d249a09387fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff253142fd440b1b4a8f20df141d565",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edff557bd3f246b89ebe09381a1881f8",
            "value": 481
          }
        },
        "a4f68d02cb834ebd895e7fdf41959d54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7a44bcab41e4954a655b4787655bed4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9e20f8d46d74b20bc157c461bb62cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a5cc7f0d06e4fce913a22df25a9d127",
            "placeholder": "​",
            "style": "IPY_MODEL_501aa57e82ad46fb96d4d6120cc994e7",
            "value": "Downloading: 100%"
          }
        },
        "ac13b6dad99547cba2c891c24234de24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac528520c184457e93466216396c57a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acb1410b22604405bb39df6874e787a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeed034b61e54f9aa8e726ce70ebe0ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a278e1f13f21412e86f224ac51dd9256",
              "IPY_MODEL_baefbd45994147fa92a746c134420327",
              "IPY_MODEL_52fc72ada16e49e784572c8e6eab371b"
            ],
            "layout": "IPY_MODEL_5ee71b54d154405c8a095cb9a5f784f3"
          }
        },
        "b7d433c587944ebfacec26e74c974757": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec880502c76f45fe930afedd067a5d5a",
              "IPY_MODEL_6156cc960aa24aaba6ec1691672d9f54",
              "IPY_MODEL_773d45ac413040c0a662257990601b39"
            ],
            "layout": "IPY_MODEL_84abb2c467414a8191bcb1e8e1c4dc08"
          }
        },
        "b89fd22ebe9048678b4fc528245dd51c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baefbd45994147fa92a746c134420327": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_841045df6c174819af05ddcd6a5c02e6",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46182b2df7724202b85a54194ea67dfe",
            "value": 501200538
          }
        },
        "bb09cc12a4874e6381ed0febf28cb216": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd9c6297bf07477d95fc7947c4d1d61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55ee5bfaea0e477f9f046f91b977e23f",
            "placeholder": "​",
            "style": "IPY_MODEL_4aa634def35b4d4cb0f666cc919336d6",
            "value": " 420M/420M [00:30&lt;00:00, 35.5MB/s]"
          }
        },
        "c5c4a4d529bc4f3d87a43e51fbe57aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f68d02cb834ebd895e7fdf41959d54",
            "placeholder": "​",
            "style": "IPY_MODEL_ac13b6dad99547cba2c891c24234de24",
            "value": " 878k/878k [00:01&lt;00:00, 1.18MB/s]"
          }
        },
        "c888985193e843ceb0c7e31df0299c05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca39a5daada94d0e8480926f13cc5f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6acf3c68d6184a04837cf24bf2cb94bc",
            "placeholder": "​",
            "style": "IPY_MODEL_acb1410b22604405bb39df6874e787a8",
            "value": "Downloading: 100%"
          }
        },
        "cd852e5519df4156a7e6bc6614f04c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c888985193e843ceb0c7e31df0299c05",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e1d331ca0164f83b95f8521bbd836cf",
            "value": 456318
          }
        },
        "cde0e0432e5e48c29f9017693f0b3de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3e75ffce65a4defbcbec0c5fbeb68ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a44bcab41e4954a655b4787655bed4",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9560c45379ab4c8ea59aed294bd8a326",
            "value": 440473133
          }
        },
        "e04880628587407caec125f954b6fa32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ca8f36b2404f5180f3a40d9d717ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_694eb34475b546eba7a3823cdd8b438d",
              "IPY_MODEL_017d33c4d33c46868e5cc1bd48302356",
              "IPY_MODEL_910de5f313ab4502aa2e8eb2961a2ccc"
            ],
            "layout": "IPY_MODEL_6df015ed8c5d47e981e4b992f7a53e94"
          }
        },
        "eae671af63674b4eb483cf7f8ff803b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebfbfb8de8ec4094b50147d7ae4578a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec880502c76f45fe930afedd067a5d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46763a55a76d40bfb23a411b03871fce",
            "placeholder": "​",
            "style": "IPY_MODEL_37245d607fa045c583e7bd1c3eecf4d7",
            "value": "Downloading: 100%"
          }
        },
        "edff557bd3f246b89ebe09381a1881f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef84c9cdb7d9430da5357fe4659048c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9e20f8d46d74b20bc157c461bb62cd0",
              "IPY_MODEL_cd852e5519df4156a7e6bc6614f04c1d",
              "IPY_MODEL_643671c34af8410a8e7485f06140a628"
            ],
            "layout": "IPY_MODEL_18844d6722124384aa6e59a661d5d28f"
          }
        },
        "f0edf25d82194d95b66d2e3a0a68d31e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b4e0a4860c145e3b64acc3f6bf5e186",
            "placeholder": "​",
            "style": "IPY_MODEL_90986fb49951441582e8cf8c3c1e085d",
            "value": "Downloading: 100%"
          }
        },
        "f5985cc269824b1d9b1da22ec14dabe9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa1e04ed28304200b628d77f47b7b69c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fca809eda7464f0fbabd2b1334d482a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd29cc33f3cb4e5195263e0a0b82af67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}